{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Bienvenido a VocalParam","text":"<p>VocalParam es un sistema de c\u00f3digo abierto dise\u00f1ado para unificar el proceso de grabaci\u00f3n y configuraci\u00f3n de voicebanks para s\u00edntesis vocal (UTAU/OpenUtau).</p>"},{"location":"#status-quo-sprint-3-finalizado-visual-editor-dsp","title":"Status Quo: Sprint 3 Finalizado (Visual Editor &amp; DSP)","text":"<p>Actualmente el proyecto ha completado su n\u00facleo visual y de an\u00e1lisis. Contamos con un editor interactivo con espectrograma, sincronizaci\u00f3n bidireccional y un generador OTO autom\u00e1tico inteligente, adem\u00e1s de un motor de grabaci\u00f3n profesional refinado.</p>"},{"location":"#filosofia-del-proyecto-el-zero-switch","title":"Filosof\u00eda del Proyecto: El \"Zero-Switch\"","text":"<p>Desde su concepci\u00f3n, VocalParam ha sido dise\u00f1ado bajo la premisa de eliminar el cambio constante de aplicaciones durante la creaci\u00f3n de un voicebank. Tradicionalmente, un creador debe grabar en OREMO y luego parametrizar en SetParam o vLabeler. </p> <p>Nuestra filosof\u00eda Zero-Switch unifica estas fases: - Calidad en el Origen: Al visualizar y escuchar mientras grabas, detectas errores fon\u00e9ticos al instante. - Flujo Sofisticado: Una interfaz premium que respeta la precisi\u00f3n t\u00e9cnica exigida por los motores de s\u00edntesis vocal modernos.</p>"},{"location":"#caracteristicas-principales","title":"Caracter\u00edsticas Principales","text":"<ul> <li>Grabaci\u00f3n 7-Moras Pro: Metr\u00f3nomo de baja latencia con Count-in s\u00f3nico y visual.</li> <li>WaveformCanvas Interactivo: Editor visual con Espectrograma STFT, RMS y drag-and-drop de marcadores.</li> <li>Auto-Oto H\u00edbrido: Generaci\u00f3n autom\u00e1tica de par\u00e1metros bas\u00e1ndose en BPM y an\u00e1lisis DSP de transientes.</li> <li>Sincronizaci\u00f3n Bidireccional: Edici\u00f3n fluida entre la tabla de par\u00e1metros y el visor visual.</li> <li>Gesti\u00f3n de Recursos: Control total sobre carpetas de destino y escucha integrada (Play/Listen).</li> </ul>"},{"location":"#estructura-del-proyecto","title":"Estructura del Proyecto","text":"<p>El proyecto sigue una arquitectura MVC (Modelo-Vista-Controlador) para asegurar que sea f\u00e1cil de mantener y escalar.</p> <pre><code>graph TD\n    UI[Interfaz de Usuario] --&gt; Controller[Controladores]\n    Controller --&gt; Core[L\u00f3gica Core / Modelos]\n    Core --&gt; Files[(Archivos WAV/INI)]\n</code></pre> <p>Consulte la Gu\u00eda de Usuario para empezar.</p>"},{"location":"architecture/","title":"Arquitectura del Sistema","text":"<p>VocalParam est\u00e1 construido con una arquitectura MVC desacoplada para permitir escalabilidad y portabilidad a C++.</p>"},{"location":"architecture/#componentes","title":"Componentes","text":""},{"location":"architecture/#core-modelo","title":"Core (Modelo)","text":"<p>Contiene la l\u00f3gica de negocio pura: - <code>ReclistParser</code>: An\u00e1lisis fon\u00e9tico. - <code>AudioEngine</code>: I/O de audio (sounddevice). - <code>DSPAnalyzer</code>: Algoritmos de pitch y transientes. - <code>OtoGenerator</code>: C\u00e1lculo de par\u00e1metros.</p>"},{"location":"architecture/#ui-vista","title":"UI (Vista)","text":"<p>Widgets de PyQt6: - <code>MainWindow</code>: Contenedor principal. - <code>RecorderWidget</code>: Metr\u00f3nomo y visualizaci\u00f3n en tiempo real. - <code>EditorWidget</code>: Edici\u00f3n visual de par\u00e1metros.</p>"},{"location":"architecture/#controllers-controlador","title":"Controllers (Controlador)","text":"<p>Orquestan la interacci\u00f3n entre el usuario y el core.</p>"},{"location":"architecture/#flujo-de-datos","title":"Flujo de Datos","text":"<ol> <li>El usuario interact\u00faa con la UI.</li> <li>El Controlador recibe la se\u00f1al y solicita datos al Core.</li> <li>El Core procesa y devuelve objetos de datos (<code>OtoEntry</code>, <code>PhoneticLine</code>).</li> <li>El Controlador actualiza la UI.</li> </ol>"},{"location":"changelog/","title":"Historial de Cambios (Changelog)","text":"<p>Este documento registra todas las actualizaciones significativas y mejoras t\u00e9cnicas de VocalParam, clasificadas por fases y hitos del Plan Maestro.</p>"},{"location":"changelog/#v100-prototype-febrero-2026-sprint-3","title":"[v1.0.0-prototype] - Febrero 2026 (Sprint 3)","text":""},{"location":"changelog/#nuevas-funcionalidades","title":"\u2728 Nuevas Funcionalidades","text":"<ul> <li>Editor Visual Interactivo: Implementaci\u00f3n de <code>WaveformCanvas</code> con soporte para espectrograma STFT (Hann 2048) y envolvente RMS.</li> <li>Sistema de Marcadores: 5 marcadores interactivos (Offset, Consonant, Cutoff, Pre-utterance, Overlap) con drag-and-drop sincronizado.</li> <li>Auto-OTO H\u00edbrido: Generaci\u00f3n autom\u00e1tica de par\u00e1metros basada en transientes de audio y rejilla de BPM.</li> <li>Grabaci\u00f3n Pro-UX: Implementaci\u00f3n de cuenta regresiva (3-beat count-in) y metr\u00f3nomo persistente sin interrupciones (\"glitch-free\").</li> <li>Garant\u00eda de Cola (Right Blank): Duraci\u00f3n m\u00ednima de 4 segundos para asegurar espacio suficiente para la configuraci\u00f3n de la nota.</li> <li>Validaci\u00f3n en Tiempo Real: Bloqueo autom\u00e1tico de configuraciones inv\u00e1lidas (Regla de Oro: Overlap &gt; Preutterance).</li> </ul>"},{"location":"changelog/#correcciones-y-refinamientos","title":"\ud83d\udc1b Correcciones y Refinamientos","text":"<ul> <li>Metr\u00f3nomo Fluido: Uso de <code>sd.OutputStream</code> persistente para eliminar el audio choppy/trabado en Windows.</li> <li>Sincronizaci\u00f3n Bidireccional: Los cambios manuales en la tabla de par\u00e1metros actualizan la posici\u00f3n visual del marcador instant\u00e1neamente.</li> <li>Detecci\u00f3n de Silencio de Preparaci\u00f3n: El algoritmo de OTO ahora ignora inteligentemente el periodo de \"Count-in\" para fijar el <code>Offset</code> con precisi\u00f3n.</li> </ul>"},{"location":"changelog/#v100-prototype-enero-2026","title":"[v1.0.0-prototype] - Enero 2026","text":""},{"location":"changelog/#nuevas-funcionalidades_1","title":"\u2728 Nuevas Funcionalidades","text":"<ul> <li>Motor de Audio V2: Reescritura del sistema de captura para soportar par\u00e1metros de hardware din\u00e1micos.</li> <li>WaveformScope DSP: Nuevo widget de visualizaci\u00f3n de ondas en tiempo real con alta sensibilidad y indicadores de nivel (Verde/Rojo).</li> <li>Selector de Destino Inteligente: Permite cambiar la ruta de las grabaciones directamente desde el panel principal.</li> <li>Bot\u00f3n Play/Listen: Verificaci\u00f3n inmediata de la calidad capturada antes de aceptar la toma.</li> <li>Sistema de Puntuaci\u00f3n de Dispositivos: Detecci\u00f3n autom\u00e1tica y priorizaci\u00f3n de hardware Pro (ASIO, Focusrite, etc.).</li> </ul>"},{"location":"changelog/#correcciones-criticas-fixes","title":"\ud83d\udc1b Correcciones Cr\u00edticas (Fixes)","text":"<ul> <li>Sincronizaci\u00f3n Mora 0: Eliminado el desfase inicial; el metr\u00f3nomo ahora es p\u00edxel-perfecto desde el primer milisegundo.</li> <li>Corrupci\u00f3n de WAV (44 bytes): Se corrigi\u00f3 el error donde el buffer se sobreescrib\u00eda al presionar \"Aceptar\", garantizando que lo que se graba es lo que se guarda.</li> <li>Corte Prematuro (Tail Recording): Implementado el \"Tail Beat\" de un pulso extra para asegurar que las terminaciones vocales no se corten.</li> <li>Barra de Progreso: Sincronizada con <code>time.time()</code> para ofrecer un movimiento fluido al 100%.</li> <li>Error \"Invalid Device\" en Windows: Implementado retraso de seguridad y gesti\u00f3n de bloqueos (<code>threading.Lock</code>) para liberar el hardware apropiadamente.</li> </ul>"},{"location":"changelog/#documentacion","title":"\ud83d\udcdd Documentaci\u00f3n","text":"<ul> <li>Lanzamiento del sitio web oficial con arquitectura t\u00e9cnica y manual de usuario.</li> <li>Integraci\u00f3n de la filosof\u00eda Zero-Switch en toda la comunicaci\u00f3n del proyecto.</li> <li>Nueva p\u00e1gina de Plan y Progreso (Roadmap) para transparencia total.</li> </ul>"},{"location":"changelog/#historial-de-commits-recientes","title":"Historial de Commits Recientes","text":"Hash Mensaje <code>d6fce89</code> feat: cumulative updates for VocalParam v1.0 master plan (Fases 1-5) <code>b40ed08</code> docs: add development plan and roadmap page <code>0b86556</code> feat: implement path selector, playback button, and metronome sync fix <code>ba8dd5e</code> docs: update with Zero-Switch philosophy <p>[!TIP] Puedes ver el detalle completo en el Repositorio de GitHub.</p>"},{"location":"roadmap/","title":"Plan de Desarrollo y Progreso","text":"<p>VocalParam es un proyecto ambicioso que busca redefinir la creaci\u00f3n de voicebanks. Este documento detalla nuestra hoja de ruta, los hitos alcanzados y lo que est\u00e1 por venir.</p>"},{"location":"roadmap/#estado-actual-v100-prototype-sprint-3-completado","title":"Estado Actual: v1.0.0-prototype (Sprint 3 Completado)","text":"<p>Estamos operando bajo la filosof\u00eda Zero-Switch, unificando la grabaci\u00f3n y parametrizaci\u00f3n en una sola experiencia t\u00e9cnica de primer nivel.</p>"},{"location":"roadmap/#hoja-de-ruta-roadmap","title":"Hoja de Ruta (Roadmap)","text":""},{"location":"roadmap/#sprint-1-cimientos-y-arquitectura-core-completado","title":"\ud83d\udfe2 Sprint 1: Cimientos y Arquitectura Core (Completado)","text":"<ul> <li>[x] Configuraci\u00f3n del entorno de desarrollo (Python/PyQt6).</li> <li>[x] Implementaci\u00f3n del Motor de Audio basado en <code>sounddevice</code>.</li> <li>[x] Arquitectura MVC para escalabilidad.</li> <li>[x] Sistema de logging y manejo de errores.</li> </ul>"},{"location":"roadmap/#sprint-2-grabacion-proactiva-y-motor-de-audio-completado","title":"\ud83d\udfe2 Sprint 2: Grabaci\u00f3n Proactiva y Motor de Audio (Completado)","text":"<ul> <li>[x] Grabaci\u00f3n 7-Moras: Metr\u00f3nomo visual y auditivo de alta precisi\u00f3n.</li> <li>[x] Gesti\u00f3n de Archivos: Selector de destino integrado en el panel de grabaci\u00f3n.</li> <li>[x] Control de Calidad: Bot\u00f3n Play/Listen para verificaci\u00f3n inmediata.</li> <li>[x] Sincronizaci\u00f3n Cr\u00edtica: Correcci\u00f3n del desfase en Mora 0 (sincronizaci\u00f3n instant\u00e1nea).</li> <li>[x] Motor de Audio V2: Gesti\u00f3n segura de hardware (Windows Fix) y headers WAV din\u00e1micos.</li> <li>[x] Visualizaci\u00f3n DSP: WaveformScope de alta precisi\u00f3n con indicadores de nivel.</li> <li>[x] Sincronizaci\u00f3n de Tiempo: Barra de progreso sincronizada en tiempo real (<code>time.time()</code>).</li> <li>[x] Grabaci\u00f3n Pro-UX: Implementaci\u00f3n de Count-in y metr\u00f3nomo persistente \"Glitch-free\".</li> </ul>"},{"location":"roadmap/#sprint-3-editor-visual-y-auto-oto-completado","title":"\ud83d\udfe2 Sprint 3: Editor Visual y Auto-OTO (Completado)","text":"<ul> <li>[x] WaveformCanvas: Visualizador interactivo con Espectrograma STFT y RMS.</li> <li>[x] Sistema de Marcadores: Controladores visuales sincronizados para los 5 par\u00e1metros OTO.</li> <li>[x] Sincronizaci\u00f3n Bidireccional: Tabla de par\u00e1metros &lt;-&gt; Editor Visual en tiempo real.</li> <li>[x] Algoritmo Auto-OTO: Detecci\u00f3n inteligente de transientes para posicionamiento inicial de Offset.</li> <li>[x] Validaci\u00f3n de Reglas: Implementaci\u00f3n de la \"Regla de Oro\" (Overlap &lt;= Pre-utterance).</li> </ul>"},{"location":"roadmap/#sprint-4-inteligencia-y-automatizacion-siguiente","title":"\u26aa Sprint 4: Inteligencia y Automatizaci\u00f3n (Siguiente)","text":"<ul> <li>[ ] Refinamiento del algoritmo de detecci\u00f3n fon\u00e9tica (espec\u00edfico por fonema).</li> <li>[ ] Soporte para diferentes idiomas y estilos de grabaci\u00f3n.</li> <li>[ ] Herramientas de diagn\u00f3stico de calidad vocal.</li> </ul>"},{"location":"roadmap/#sprint-5-exportacion-y-compatibilidad","title":"\u26aa Sprint 5: Exportaci\u00f3n y Compatibilidad","text":"<ul> <li>[ ] Exportaci\u00f3n completa garantizada para UTAU y OpenUtau.</li> <li>[ ] Empaquetado de Voicebanks (.zip).</li> <li>[ ] Importador de proyectos legacy de OREMO/SetParam.</li> </ul>"},{"location":"roadmap/#sprint-6-pulido-y-lanzamiento-v10-stable","title":"\u26aa Sprint 6: Pulido y Lanzamiento v1.0 Stable","text":"<ul> <li>[ ] Optimizaci\u00f3n de rendimiento.</li> <li>[ ] Temas visuales personalizados.</li> <li>[ ] Documentaci\u00f3n extensiva y tutoriales en video.</li> </ul>"},{"location":"roadmap/#logros-recientes","title":"Logros Recientes","text":"<ul> <li>Febrero 2026: Finalizaci\u00f3n del Sprint 3 (Editor Visual y DSP Avanzado).</li> <li>Febrero 2026: Implementaci\u00f3n del flujo de grabaci\u00f3n con Count-in y metr\u00f3nomo de baja latencia.</li> <li>Enero 2026: Implementaci\u00f3n del flujo unificado de grabaci\u00f3n.</li> <li>Enero 2026: Resoluci\u00f3n de problemas cr\u00edticos de hardware de audio en Windows.</li> <li>Enero 2026: Lanzamiento de la documentaci\u00f3n t\u00e9cnica centralizada.</li> </ul> <p>[!NOTE] Nuestro progreso se gu\u00eda por el feedback de la comunidad y la b\u00fasqueda de la perfecci\u00f3n t\u00e9cnica en cada mora grabada.</p>"},{"location":"user_guide/","title":"Gu\u00eda de Usuario: VocalParam","text":"<p>VocalParam simplifica la creaci\u00f3n de voicebanks UTAU/OpenUtau integrando la grabaci\u00f3n y la parametrizaci\u00f3n.</p>"},{"location":"user_guide/#primeros-pasos","title":"Primeros Pasos","text":""},{"location":"user_guide/#1-crear-un-proyecto","title":"1. Crear un Proyecto","text":"<p>Al abrir VocalParam, use Archivo &gt; Nuevo Proyecto. Especifique el nombre y el BPM (por defecto 120).</p>"},{"location":"user_guide/#2-cargar-reclist","title":"2. Cargar Reclist","text":"<p>Cargue su archivo <code>.txt</code> de reclist. VocalParam validar\u00e1 que siga la arquitectura de 7-Moras.</p>"},{"location":"user_guide/#3-grabacion-proactiva-y-control-de-calidad","title":"3. Grabaci\u00f3n Proactiva y Control de Calidad","text":"<ol> <li>Seleccione una l\u00ednea en el panel izquierdo.</li> <li>Configure el Destino: En la parte superior del panel de grabaci\u00f3n, verifique o cambie la carpeta donde se guardar\u00e1n los WAVs usando el bot\u00f3n <code>...</code>.</li> <li>Presione <code>Space</code> para iniciar el metr\u00f3nomo.</li> <li>Sincronizaci\u00f3n Perfecta: Pronuncie cada s\u00edlaba sincronizada con el click. Note que el primer recuadro se activa instant\u00e1neamente al iniciar para una referencia precisa.</li> <li>Al finalizar los 7 golpes, use el bot\u00f3n \u25b6 Escuchar / Listen para verificar su toma.</li> <li>Si la toma es correcta, presione Aceptar (Enter) para guardar el archivo y avanzar. De lo contrario, presione R para repetir.</li> </ol>"},{"location":"user_guide/#4-generacion-de-otoini","title":"4. Generaci\u00f3n de oto.ini","text":"<p>Presione Proyecto &gt; Generar oto.ini. El sistema usar\u00e1 el algoritmo h\u00edbrido para calcular los par\u00e1metros bas\u00e1ndose en el ritmo y an\u00e1lisis DSP.</p>"},{"location":"user_guide/#5-ajuste-fino","title":"5. Ajuste Fino","text":"<p>Use el Editor Visual para arrastrar las l\u00edneas de par\u00e1metros: - Cian: Offset - Verde: Overlap - Rojo: Pre-utterance - Azul: Consonant - Rosa: Cutoff</p>"},{"location":"workflow/","title":"Flujo de Trabajo Profesional","text":"<p>Este proyecto sigue est\u00e1ndares de la industria para asegurar la calidad y automatizaci\u00f3n.</p>"},{"location":"workflow/#automatizacion-con-cicd","title":"Automatizaci\u00f3n con CI/CD","text":"<p>VocalParam usa GitHub Actions para: - Validaci\u00f3n: Cada cambio enviado a GitHub activa los tests unitarios. - Documentaci\u00f3n en Vivo: Si los tests pasan, el manual se actualiza autom\u00e1ticamente en la web del proyecto.</p>"},{"location":"workflow/#reglas-de-commits","title":"Reglas de Commits","text":"<p>Usamos Conventional Commits: - <code>feat</code>: Nuevas caracter\u00edsticas. - <code>fix</code>: Correcciones. - <code>docs</code>: Documentaci\u00f3n. - <code>refactor</code>: Mejoras de c\u00f3digo.</p>"},{"location":"workflow/#desarrollo-basado-en-tests-tdd","title":"Desarrollo Basado en Tests (TDD)","text":"<p>Cada componente core tiene su suite de pruebas correspondiente en el directorio <code>tests/</code>. Esto permite que el proyecto sea robusto ante cambios repentinos de arquitectura.</p>"},{"location":"reference/core/","title":"Referencia Core","text":"<p>Documentaci\u00f3n autogenerada de los m\u00f3dulos core.</p> <p>Reclist Parser module.</p> <p>This module handles parsing of 7-Mora reclist files for VCV voicebanks. Based on Section 6, M\u00d3DULO 1 specification.</p> <p>Data models for VocalParam.</p> <p>This module contains all dataclasses and enums used throughout the application. Following the specification in Section 6-7 of the design document.</p>"},{"location":"reference/core/#core.reclist_parser.ReclistParseError","title":"<code>ReclistParseError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised when reclist parsing fails.</p> <p>Attributes:</p> Name Type Description <code>line_number</code> <p>The line number where the error occurred</p> <code>line_content</code> <p>The content of the problematic line</p> <code>message</code> <p>Detailed error message</p> Source code in <code>src/core/reclist_parser.py</code> <pre><code>class ReclistParseError(Exception):\n    \"\"\"Exception raised when reclist parsing fails.\n\n    Attributes:\n        line_number: The line number where the error occurred\n        line_content: The content of the problematic line\n        message: Detailed error message\n    \"\"\"\n\n    def __init__(self, message: str, line_number: int = 0, line_content: str = \"\"):\n        self.line_number = line_number\n        self.line_content = line_content\n        self.message = message\n        super().__init__(self._format_message())\n\n    def _format_message(self) -&gt; str:\n        if self.line_number &gt; 0:\n            return f\"Error en l\u00ednea {self.line_number}: {self.message}\\nContenido: '{self.line_content}'\"\n        return self.message\n</code></pre>"},{"location":"reference/core/#core.reclist_parser.ReclistParser","title":"<code>ReclistParser</code>","text":"<p>Parser for 7-Mora VCV reclist files.</p> <p>Analyzes reclist text files and converts them into structured PhoneticLine objects with metadata for each line.</p> <p>The parser identifies: - Pure vowels (VV): a_a_i_a_u_e_o - Basic consonants (CV): ba_be_bi_bo_bu_ba_b - Clusters (CCR/CCL): pra_pre_pri... - Diphthongs (DIP): kya_kyu_kyo... - Breaths (R): R or breath markers</p> Example <p>parser = ReclistParser(bpm=120) lines = parser.parse_file(\"reclist.txt\") print(lines[0].segments) ['a', 'a', 'i', 'a', 'u', 'e', 'o']</p> Source code in <code>src/core/reclist_parser.py</code> <pre><code>class ReclistParser:\n    \"\"\"Parser for 7-Mora VCV reclist files.\n\n    Analyzes reclist text files and converts them into structured\n    PhoneticLine objects with metadata for each line.\n\n    The parser identifies:\n    - Pure vowels (VV): a_a_i_a_u_e_o\n    - Basic consonants (CV): ba_be_bi_bo_bu_ba_b\n    - Clusters (CCR/CCL): pra_pre_pri...\n    - Diphthongs (DIP): kya_kyu_kyo...\n    - Breaths (R): R or breath markers\n\n    Example:\n        &gt;&gt;&gt; parser = ReclistParser(bpm=120)\n        &gt;&gt;&gt; lines = parser.parse_file(\"reclist.txt\")\n        &gt;&gt;&gt; print(lines[0].segments)\n        ['a', 'a', 'i', 'a', 'u', 'e', 'o']\n    \"\"\"\n\n    # Spanish/Common vowels\n    VOWELS: Set[str] = {\"a\", \"e\", \"i\", \"o\", \"u\"}\n\n    # Common consonant patterns\n    CONSONANTS: Set[str] = {\n        \"b\", \"c\", \"ch\", \"d\", \"f\", \"g\", \"h\", \"j\", \"k\", \"l\", \"ll\",\n        \"m\", \"n\", \"\u00f1\", \"p\", \"q\", \"r\", \"rr\", \"s\", \"t\", \"v\", \"w\",\n        \"x\", \"y\", \"z\"\n    }\n\n    # Consonant clusters\n    CLUSTERS: Set[str] = {\n        \"br\", \"bl\", \"cr\", \"cl\", \"dr\", \"fl\", \"fr\", \"gl\", \"gr\",\n        \"kr\", \"pl\", \"pr\", \"tr\", \"tl\"\n    }\n\n    # Breath/silence markers\n    BREATH_MARKERS: Set[str] = {\"R\", \"r\", \"breath\", \"br\", \"\u606f\"}\n\n    def __init__(self, bpm: int = DEFAULT_BPM):\n        \"\"\"Initialize parser with BPM for duration calculations.\n\n        Args:\n            bpm: Beats per minute for timing calculations\n        \"\"\"\n        self.bpm = bpm\n        self._ms_per_mora = ms_per_beat(bpm)\n\n    def parse_file(self, filepath: str) -&gt; List[PhoneticLine]:\n        \"\"\"Parse a reclist file and return list of PhoneticLine objects.\n\n        Args:\n            filepath: Path to the reclist .txt file\n\n        Returns:\n            List of PhoneticLine objects with complete metadata\n\n        Raises:\n            ReclistParseError: If the file format is invalid\n            FileNotFoundError: If the file doesn't exist\n        \"\"\"\n        path = Path(filepath)\n\n        if not path.exists():\n            raise FileNotFoundError(f\"Reclist file not found: {filepath}\")\n\n        if not path.suffix.lower() == \".txt\":\n            raise ReclistParseError(\n                \"Reclist must be a .txt file\",\n                line_content=filepath\n            )\n\n        try:\n            content = path.read_text(encoding=\"utf-8\")\n        except UnicodeDecodeError:\n            # Try with other common encodings\n            try:\n                content = path.read_text(encoding=\"shift-jis\")\n            except UnicodeDecodeError:\n                content = path.read_text(encoding=\"latin-1\")\n\n        return self.parse_content(content)\n\n    def parse_content(self, content: str) -&gt; List[PhoneticLine]:\n        \"\"\"Parse reclist content string.\n\n        Args:\n            content: Raw text content of reclist\n\n        Returns:\n            List of PhoneticLine objects\n\n        Raises:\n            ReclistParseError: If content format is invalid\n        \"\"\"\n        lines = content.strip().split(\"\\n\")\n        phonetic_lines: List[PhoneticLine] = []\n\n        for line_num, raw_line in enumerate(lines, start=1):\n            # Skip empty lines and comments\n            stripped = raw_line.strip()\n            if not stripped or stripped.startswith(\"#\") or stripped.startswith(\"//\"):\n                continue\n\n            try:\n                phonetic_line = self._parse_line(stripped, line_num)\n                phonetic_lines.append(phonetic_line)\n            except ReclistParseError:\n                raise\n            except Exception as e:\n                raise ReclistParseError(\n                    f\"Error inesperado: {str(e)}\",\n                    line_number=line_num,\n                    line_content=stripped\n                )\n\n        if not phonetic_lines:\n            raise ReclistParseError(\"El archivo reclist est\u00e1 vac\u00edo o no contiene l\u00edneas v\u00e1lidas\")\n\n        return phonetic_lines\n\n    def _parse_line(self, line: str, line_number: int) -&gt; PhoneticLine:\n        \"\"\"Parse a single reclist line.\n\n        Args:\n            line: Raw line text (e.g., \"ba_be_bi_bo_bu_ba_b\")\n            line_number: Line number for error reporting\n\n        Returns:\n            PhoneticLine with parsed segments\n        \"\"\"\n        # Split by underscore (standard reclist format)\n        segments = line.split(\"_\")\n\n        # Detect phoneme types for each segment\n        phoneme_types = [self.detect_phoneme_type(seg) for seg in segments]\n\n        # Generate filename from line content\n        filename = f\"{line}.wav\"\n\n        # Calculate expected duration\n        expected_duration = self._ms_per_mora * len(segments)\n\n        return PhoneticLine(\n            index=line_number,\n            raw_text=line,\n            segments=segments,\n            phoneme_types=phoneme_types,\n            expected_duration_ms=expected_duration,\n            filename=filename,\n        )\n\n    def validate_mora_count(self, line: str, expected: int = MORAS_PER_LINE) -&gt; bool:\n        \"\"\"Verify that the line has the expected number of moras.\n\n        Args:\n            line: Raw line text\n            expected: Expected mora count (default: 7)\n\n        Returns:\n            True if mora count matches expected\n        \"\"\"\n        segments = line.split(\"_\")\n        return len(segments) == expected\n\n    def detect_phoneme_type(self, segment: str) -&gt; PhonemeType:\n        \"\"\"Classify a phoneme segment into its type.\n\n        Args:\n            segment: Individual segment (e.g., \"ba\", \"a\", \"pra\")\n\n        Returns:\n            PhonemeType classification\n        \"\"\"\n        segment_lower = segment.lower()\n\n        # Check for breath markers\n        if segment_lower in self.BREATH_MARKERS or segment_lower == \"\":\n            return PhonemeType.R\n\n        # Pure vowel (single vowel character)\n        if segment_lower in self.VOWELS:\n            return PhonemeType.VV\n\n        # Check for consonant clusters at start (CCR/CCL)\n        for cluster in self.CLUSTERS:\n            if segment_lower.startswith(cluster):\n                return PhonemeType.CCR\n\n        # Check for diphthongs (consonant + y/w + vowel)\n        diphthong_pattern = re.compile(r'^[bcdfghjklmnpqrstvwxyz]+[yw][aeiou]$', re.IGNORECASE)\n        if diphthong_pattern.match(segment_lower):\n            return PhonemeType.DIP\n\n        # Check if ends with vowel (CV pattern)\n        if segment_lower and segment_lower[-1] in self.VOWELS:\n            # Check if it's a VCV pattern (vowel + consonant + vowel)\n            if len(segment_lower) &gt;= 3 and segment_lower[0] in self.VOWELS:\n                return PhonemeType.VCV\n            return PhonemeType.CV\n\n        # Ends with consonant (VC pattern or standalone consonant)\n        if segment_lower and segment_lower[-1] not in self.VOWELS:\n            if segment_lower[0] in self.VOWELS:\n                return PhonemeType.VC\n            # Standalone consonant (like \"b\" at end of ba_be_bi_bo_bu_ba_b)\n            return PhonemeType.CV\n\n        # Default to CV for unrecognized patterns\n        return PhonemeType.CV\n\n    def get_line_summary(self, line: PhoneticLine) -&gt; str:\n        \"\"\"Generate a human-readable summary of a phonetic line.\n\n        Args:\n            line: PhoneticLine to summarize\n\n        Returns:\n            Formatted summary string\n        \"\"\"\n        type_counts = {}\n        for ptype in line.phoneme_types:\n            type_counts[ptype.name] = type_counts.get(ptype.name, 0) + 1\n\n        type_summary = \", \".join(f\"{k}:{v}\" for k, v in type_counts.items())\n\n        return (\n            f\"L\u00ednea {line.index:03d}: {line.raw_text}\\n\"\n            f\"  Segmentos: {line.mora_count} | Duraci\u00f3n: {line.expected_duration_ms:.1f}ms\\n\"\n            f\"  Tipos: {type_summary}\"\n        )\n</code></pre>"},{"location":"reference/core/#core.reclist_parser.ReclistParser.__init__","title":"<code>__init__(bpm=DEFAULT_BPM)</code>","text":"<p>Initialize parser with BPM for duration calculations.</p> <p>Parameters:</p> Name Type Description Default <code>bpm</code> <code>int</code> <p>Beats per minute for timing calculations</p> <code>DEFAULT_BPM</code> Source code in <code>src/core/reclist_parser.py</code> <pre><code>def __init__(self, bpm: int = DEFAULT_BPM):\n    \"\"\"Initialize parser with BPM for duration calculations.\n\n    Args:\n        bpm: Beats per minute for timing calculations\n    \"\"\"\n    self.bpm = bpm\n    self._ms_per_mora = ms_per_beat(bpm)\n</code></pre>"},{"location":"reference/core/#core.reclist_parser.ReclistParser.detect_phoneme_type","title":"<code>detect_phoneme_type(segment)</code>","text":"<p>Classify a phoneme segment into its type.</p> <p>Parameters:</p> Name Type Description Default <code>segment</code> <code>str</code> <p>Individual segment (e.g., \"ba\", \"a\", \"pra\")</p> required <p>Returns:</p> Type Description <code>PhonemeType</code> <p>PhonemeType classification</p> Source code in <code>src/core/reclist_parser.py</code> <pre><code>def detect_phoneme_type(self, segment: str) -&gt; PhonemeType:\n    \"\"\"Classify a phoneme segment into its type.\n\n    Args:\n        segment: Individual segment (e.g., \"ba\", \"a\", \"pra\")\n\n    Returns:\n        PhonemeType classification\n    \"\"\"\n    segment_lower = segment.lower()\n\n    # Check for breath markers\n    if segment_lower in self.BREATH_MARKERS or segment_lower == \"\":\n        return PhonemeType.R\n\n    # Pure vowel (single vowel character)\n    if segment_lower in self.VOWELS:\n        return PhonemeType.VV\n\n    # Check for consonant clusters at start (CCR/CCL)\n    for cluster in self.CLUSTERS:\n        if segment_lower.startswith(cluster):\n            return PhonemeType.CCR\n\n    # Check for diphthongs (consonant + y/w + vowel)\n    diphthong_pattern = re.compile(r'^[bcdfghjklmnpqrstvwxyz]+[yw][aeiou]$', re.IGNORECASE)\n    if diphthong_pattern.match(segment_lower):\n        return PhonemeType.DIP\n\n    # Check if ends with vowel (CV pattern)\n    if segment_lower and segment_lower[-1] in self.VOWELS:\n        # Check if it's a VCV pattern (vowel + consonant + vowel)\n        if len(segment_lower) &gt;= 3 and segment_lower[0] in self.VOWELS:\n            return PhonemeType.VCV\n        return PhonemeType.CV\n\n    # Ends with consonant (VC pattern or standalone consonant)\n    if segment_lower and segment_lower[-1] not in self.VOWELS:\n        if segment_lower[0] in self.VOWELS:\n            return PhonemeType.VC\n        # Standalone consonant (like \"b\" at end of ba_be_bi_bo_bu_ba_b)\n        return PhonemeType.CV\n\n    # Default to CV for unrecognized patterns\n    return PhonemeType.CV\n</code></pre>"},{"location":"reference/core/#core.reclist_parser.ReclistParser.get_line_summary","title":"<code>get_line_summary(line)</code>","text":"<p>Generate a human-readable summary of a phonetic line.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>PhoneticLine</code> <p>PhoneticLine to summarize</p> required <p>Returns:</p> Type Description <code>str</code> <p>Formatted summary string</p> Source code in <code>src/core/reclist_parser.py</code> <pre><code>def get_line_summary(self, line: PhoneticLine) -&gt; str:\n    \"\"\"Generate a human-readable summary of a phonetic line.\n\n    Args:\n        line: PhoneticLine to summarize\n\n    Returns:\n        Formatted summary string\n    \"\"\"\n    type_counts = {}\n    for ptype in line.phoneme_types:\n        type_counts[ptype.name] = type_counts.get(ptype.name, 0) + 1\n\n    type_summary = \", \".join(f\"{k}:{v}\" for k, v in type_counts.items())\n\n    return (\n        f\"L\u00ednea {line.index:03d}: {line.raw_text}\\n\"\n        f\"  Segmentos: {line.mora_count} | Duraci\u00f3n: {line.expected_duration_ms:.1f}ms\\n\"\n        f\"  Tipos: {type_summary}\"\n    )\n</code></pre>"},{"location":"reference/core/#core.reclist_parser.ReclistParser.parse_content","title":"<code>parse_content(content)</code>","text":"<p>Parse reclist content string.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>Raw text content of reclist</p> required <p>Returns:</p> Type Description <code>List[PhoneticLine]</code> <p>List of PhoneticLine objects</p> <p>Raises:</p> Type Description <code>ReclistParseError</code> <p>If content format is invalid</p> Source code in <code>src/core/reclist_parser.py</code> <pre><code>def parse_content(self, content: str) -&gt; List[PhoneticLine]:\n    \"\"\"Parse reclist content string.\n\n    Args:\n        content: Raw text content of reclist\n\n    Returns:\n        List of PhoneticLine objects\n\n    Raises:\n        ReclistParseError: If content format is invalid\n    \"\"\"\n    lines = content.strip().split(\"\\n\")\n    phonetic_lines: List[PhoneticLine] = []\n\n    for line_num, raw_line in enumerate(lines, start=1):\n        # Skip empty lines and comments\n        stripped = raw_line.strip()\n        if not stripped or stripped.startswith(\"#\") or stripped.startswith(\"//\"):\n            continue\n\n        try:\n            phonetic_line = self._parse_line(stripped, line_num)\n            phonetic_lines.append(phonetic_line)\n        except ReclistParseError:\n            raise\n        except Exception as e:\n            raise ReclistParseError(\n                f\"Error inesperado: {str(e)}\",\n                line_number=line_num,\n                line_content=stripped\n            )\n\n    if not phonetic_lines:\n        raise ReclistParseError(\"El archivo reclist est\u00e1 vac\u00edo o no contiene l\u00edneas v\u00e1lidas\")\n\n    return phonetic_lines\n</code></pre>"},{"location":"reference/core/#core.reclist_parser.ReclistParser.parse_file","title":"<code>parse_file(filepath)</code>","text":"<p>Parse a reclist file and return list of PhoneticLine objects.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to the reclist .txt file</p> required <p>Returns:</p> Type Description <code>List[PhoneticLine]</code> <p>List of PhoneticLine objects with complete metadata</p> <p>Raises:</p> Type Description <code>ReclistParseError</code> <p>If the file format is invalid</p> <code>FileNotFoundError</code> <p>If the file doesn't exist</p> Source code in <code>src/core/reclist_parser.py</code> <pre><code>def parse_file(self, filepath: str) -&gt; List[PhoneticLine]:\n    \"\"\"Parse a reclist file and return list of PhoneticLine objects.\n\n    Args:\n        filepath: Path to the reclist .txt file\n\n    Returns:\n        List of PhoneticLine objects with complete metadata\n\n    Raises:\n        ReclistParseError: If the file format is invalid\n        FileNotFoundError: If the file doesn't exist\n    \"\"\"\n    path = Path(filepath)\n\n    if not path.exists():\n        raise FileNotFoundError(f\"Reclist file not found: {filepath}\")\n\n    if not path.suffix.lower() == \".txt\":\n        raise ReclistParseError(\n            \"Reclist must be a .txt file\",\n            line_content=filepath\n        )\n\n    try:\n        content = path.read_text(encoding=\"utf-8\")\n    except UnicodeDecodeError:\n        # Try with other common encodings\n        try:\n            content = path.read_text(encoding=\"shift-jis\")\n        except UnicodeDecodeError:\n            content = path.read_text(encoding=\"latin-1\")\n\n    return self.parse_content(content)\n</code></pre>"},{"location":"reference/core/#core.reclist_parser.ReclistParser.validate_mora_count","title":"<code>validate_mora_count(line, expected=MORAS_PER_LINE)</code>","text":"<p>Verify that the line has the expected number of moras.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Raw line text</p> required <code>expected</code> <code>int</code> <p>Expected mora count (default: 7)</p> <code>MORAS_PER_LINE</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if mora count matches expected</p> Source code in <code>src/core/reclist_parser.py</code> <pre><code>def validate_mora_count(self, line: str, expected: int = MORAS_PER_LINE) -&gt; bool:\n    \"\"\"Verify that the line has the expected number of moras.\n\n    Args:\n        line: Raw line text\n        expected: Expected mora count (default: 7)\n\n    Returns:\n        True if mora count matches expected\n    \"\"\"\n    segments = line.split(\"_\")\n    return len(segments) == expected\n</code></pre>"},{"location":"reference/core/#core.models.OtoEntry","title":"<code>OtoEntry</code>  <code>dataclass</code>","text":"<p>Represents a single entry in oto.ini file.</p> <p>Format: filename.wav=alias,offset,consonant,cutoff,preutter,overlap</p> <p>Attributes:</p> Name Type Description <code>filename</code> <code>str</code> <p>WAV file name</p> <code>alias</code> <code>str</code> <p>Phonetic alias (e.g., \"- ba\" or \"a be\")</p> <code>offset</code> <code>float</code> <p>Start position in ms (cian/cyan line)</p> <code>consonant</code> <code>float</code> <p>Fixed consonant region in ms (dark blue line)</p> <code>cutoff</code> <code>float</code> <p>End position in ms, negative = from end (pink/magenta line)</p> <code>preutter</code> <code>float</code> <p>Pre-utterance point in ms (red line)</p> <code>overlap</code> <code>float</code> <p>Overlap region in ms (green line)</p> Source code in <code>src/core/models.py</code> <pre><code>@dataclass\nclass OtoEntry:\n    \"\"\"Represents a single entry in oto.ini file.\n\n    Format: filename.wav=alias,offset,consonant,cutoff,preutter,overlap\n\n    Attributes:\n        filename: WAV file name\n        alias: Phonetic alias (e.g., \"- ba\" or \"a be\")\n        offset: Start position in ms (cian/cyan line)\n        consonant: Fixed consonant region in ms (dark blue line)\n        cutoff: End position in ms, negative = from end (pink/magenta line)\n        preutter: Pre-utterance point in ms (red line)\n        overlap: Overlap region in ms (green line)\n    \"\"\"\n    filename: str\n    alias: str\n    offset: float\n    consonant: float\n    cutoff: float\n    preutter: float\n    overlap: float\n    comment: str = \"\"\n\n    def to_oto_line(self) -&gt; str:\n        \"\"\"Convert to oto.ini format string.\"\"\"\n        return (\n            f\"{self.filename}={self.alias},\"\n            f\"{self.offset:.1f},{self.consonant:.1f},\"\n            f\"{self.cutoff:.1f},{self.preutter:.1f},{self.overlap:.1f}\"\n            f\" #{self.comment}\" if self.comment else \"\"\n        )\n\n    @classmethod\n    def from_oto_line(cls, line: str) -&gt; \"OtoEntry\":\n        \"\"\"Parse an oto.ini format line.\"\"\"\n        # Split filename from parameters\n        filename_part, params_part = line.strip().split(\"=\", 1)\n        parts = params_part.split(\",\")\n\n        return cls(\n            filename=filename_part,\n            alias=parts[0],\n            offset=float(parts[1]),\n            consonant=float(parts[2]),\n            cutoff=float(parts[3]),\n            preutter=float(parts[4]),\n            overlap=float(parts[5]),\n            comment=\"\" # TODO: Parse comment if present\n        )\n\n    def validate(self) -&gt; List[str]:\n        \"\"\"Validate OTO parameters.\n\n        Checks:\n        - Overlap &lt;= Preutterance (Gold Rule)\n\n        Returns:\n            List of error messages.\n        \"\"\"\n        errors = []\n        if self.overlap &gt; self.preutter:\n            errors.append(f\"Overlap ({self.overlap}) cannot be greater than Preutterance ({self.preutter})\")\n        return errors\n</code></pre>"},{"location":"reference/core/#core.models.OtoEntry.from_oto_line","title":"<code>from_oto_line(line)</code>  <code>classmethod</code>","text":"<p>Parse an oto.ini format line.</p> Source code in <code>src/core/models.py</code> <pre><code>@classmethod\ndef from_oto_line(cls, line: str) -&gt; \"OtoEntry\":\n    \"\"\"Parse an oto.ini format line.\"\"\"\n    # Split filename from parameters\n    filename_part, params_part = line.strip().split(\"=\", 1)\n    parts = params_part.split(\",\")\n\n    return cls(\n        filename=filename_part,\n        alias=parts[0],\n        offset=float(parts[1]),\n        consonant=float(parts[2]),\n        cutoff=float(parts[3]),\n        preutter=float(parts[4]),\n        overlap=float(parts[5]),\n        comment=\"\" # TODO: Parse comment if present\n    )\n</code></pre>"},{"location":"reference/core/#core.models.OtoEntry.to_oto_line","title":"<code>to_oto_line()</code>","text":"<p>Convert to oto.ini format string.</p> Source code in <code>src/core/models.py</code> <pre><code>def to_oto_line(self) -&gt; str:\n    \"\"\"Convert to oto.ini format string.\"\"\"\n    return (\n        f\"{self.filename}={self.alias},\"\n        f\"{self.offset:.1f},{self.consonant:.1f},\"\n        f\"{self.cutoff:.1f},{self.preutter:.1f},{self.overlap:.1f}\"\n        f\" #{self.comment}\" if self.comment else \"\"\n    )\n</code></pre>"},{"location":"reference/core/#core.models.OtoEntry.validate","title":"<code>validate()</code>","text":"<p>Validate OTO parameters.</p> <p>Checks: - Overlap &lt;= Preutterance (Gold Rule)</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of error messages.</p> Source code in <code>src/core/models.py</code> <pre><code>def validate(self) -&gt; List[str]:\n    \"\"\"Validate OTO parameters.\n\n    Checks:\n    - Overlap &lt;= Preutterance (Gold Rule)\n\n    Returns:\n        List of error messages.\n    \"\"\"\n    errors = []\n    if self.overlap &gt; self.preutter:\n        errors.append(f\"Overlap ({self.overlap}) cannot be greater than Preutterance ({self.preutter})\")\n    return errors\n</code></pre>"},{"location":"reference/core/#core.models.PhonemeType","title":"<code>PhonemeType</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Classification of phoneme segments.</p> <p>Based on RF-02.1 specification: - VV: Pure vowels - CV: Consonant + Vowel (basic) - VCV: Vowel-Consonant-Vowel transitions - VC: Vowel + Consonant (coda) - CCR: Consonant clusters (right) - CCL: Consonant clusters (left) - DIP: Diphthongs (palatization/labialization) - R: Breaths/respirations</p> Source code in <code>src/core/models.py</code> <pre><code>class PhonemeType(Enum):\n    \"\"\"Classification of phoneme segments.\n\n    Based on RF-02.1 specification:\n    - VV: Pure vowels\n    - CV: Consonant + Vowel (basic)\n    - VCV: Vowel-Consonant-Vowel transitions\n    - VC: Vowel + Consonant (coda)\n    - CCR: Consonant clusters (right)\n    - CCL: Consonant clusters (left)\n    - DIP: Diphthongs (palatization/labialization)\n    - R: Breaths/respirations\n    \"\"\"\n    VV = auto()   # Pure vowels (a_a_i_a_u_e_o)\n    CV = auto()   # Consonant-Vowel (ba, ka, sa...)\n    VCV = auto()  # Vowel-Consonant-Vowel transitions\n    VC = auto()   # Vowel-Consonant codas\n    CCR = auto()  # Consonant clusters (pr, tr, kr...)\n    CCL = auto()  # Consonant clusters left\n    DIP = auto()  # Diphthongs\n    R = auto()    # Breaths/respirations\n</code></pre>"},{"location":"reference/core/#core.models.PhoneticLine","title":"<code>PhoneticLine</code>  <code>dataclass</code>","text":"<p>Represents a single line from the Reclist.</p> <p>As specified in Section 6, M\u00d3DULO 1.</p> <p>Attributes:</p> Name Type Description <code>index</code> <code>int</code> <p>Line number (001, 002...)</p> <code>raw_text</code> <code>str</code> <p>Original text from reclist (e.g., \"ba_be_bi_bo_bu_ba_b\")</p> <code>segments</code> <code>List[str]</code> <p>List of individual segments (e.g., [\"ba\", \"be\", \"bi\"...])</p> <code>phoneme_types</code> <code>List[PhonemeType]</code> <p>Classification of each segment</p> <code>expected_duration_ms</code> <code>float</code> <p>Calculated duration based on BPM</p> <code>filename</code> <code>str</code> <p>Generated WAV filename</p> Source code in <code>src/core/models.py</code> <pre><code>@dataclass\nclass PhoneticLine:\n    \"\"\"Represents a single line from the Reclist.\n\n    As specified in Section 6, M\u00d3DULO 1.\n\n    Attributes:\n        index: Line number (001, 002...)\n        raw_text: Original text from reclist (e.g., \"ba_be_bi_bo_bu_ba_b\")\n        segments: List of individual segments (e.g., [\"ba\", \"be\", \"bi\"...])\n        phoneme_types: Classification of each segment\n        expected_duration_ms: Calculated duration based on BPM\n        filename: Generated WAV filename\n    \"\"\"\n    index: int\n    raw_text: str\n    segments: List[str]\n    phoneme_types: List[PhonemeType]\n    expected_duration_ms: float\n    filename: str\n\n    @property\n    def mora_count(self) -&gt; int:\n        \"\"\"Number of moras (segments) in this line.\"\"\"\n        return len(self.segments)\n</code></pre>"},{"location":"reference/core/#core.models.PhoneticLine.mora_count","title":"<code>mora_count</code>  <code>property</code>","text":"<p>Number of moras (segments) in this line.</p>"},{"location":"reference/core/#core.models.ProjectData","title":"<code>ProjectData</code>  <code>dataclass</code>","text":"<p>Complete project state for serialization (JSON).</p> <p>Based on Section 7 data model specification.</p> Source code in <code>src/core/models.py</code> <pre><code>@dataclass\nclass ProjectData:\n    \"\"\"Complete project state for serialization (JSON).\n\n    Based on Section 7 data model specification.\n    \"\"\"\n    project_name: str\n    bpm: int\n    reclist_path: str\n    output_directory: str\n    recordings: List[Recording] = field(default_factory=list)\n    created_at: datetime = field(default_factory=datetime.now)\n    last_modified: datetime = field(default_factory=datetime.now)\n    version: str = \"1.0.0\"\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"Convert to dictionary for JSON serialization.\"\"\"\n        return {\n            \"project_name\": self.project_name,\n            \"bpm\": self.bpm,\n            \"reclist_path\": self.reclist_path,\n            \"output_directory\": self.output_directory,\n            \"recordings\": [\n                {\n                    \"line_index\": r.line_index,\n                    \"filename\": r.filename,\n                    \"status\": r.status.value,\n                    \"duration_ms\": r.duration_ms,\n                    \"hash\": r.hash,\n                    \"oto_entries\": [\n                        {\n                            \"alias\": e.alias,\n                            \"offset\": e.offset,\n                            \"consonant\": e.consonant,\n                            \"cutoff\": e.cutoff,\n                            \"preutter\": e.preutter,\n                            \"overlap\": e.overlap,\n                            \"comment\": e.comment,\n                        }\n                        for e in r.oto_entries\n                    ],\n                }\n                for r in self.recordings\n            ],\n            \"metadata\": {\n                \"created_at\": self.created_at.isoformat(),\n                \"last_modified\": self.last_modified.isoformat(),\n                \"version\": self.version,\n            },\n        }\n\n    @classmethod\n    def from_dict(cls, data: dict) -&gt; \"ProjectData\":\n        \"\"\"Create ProjectData from dictionary with validation.\n\n        Raises:\n             ValueError: If required fields are missing.\n        \"\"\"\n        required_fields = [\"project_name\", \"bpm\", \"reclist_path\", \"output_directory\"]\n        missing = [f for f in required_fields if f not in data]\n        if missing:\n            raise ValueError(f\"Missing required fields in project data: {', '.join(missing)}\")\n\n        recordings = []\n        for r in data.get(\"recordings\", []):\n            oto_entries = [\n                OtoEntry(\n                    filename=r[\"filename\"],\n                    alias=e[\"alias\"],\n                    offset=e[\"offset\"],\n                    consonant=e[\"consonant\"],\n                    cutoff=e[\"cutoff\"],\n                    preutter=e[\"preutter\"],\n                    overlap=e[\"overlap\"],\n                    comment=e.get(\"comment\", \"\"),\n                )\n                for e in r.get(\"oto_entries\", [])\n            ]\n            recordings.append(Recording(\n                line_index=r[\"line_index\"],\n                filename=r[\"filename\"],\n                status=RecordingStatus(r[\"status\"]),\n                duration_ms=r.get(\"duration_ms\", 0.0),\n                hash=r.get(\"hash\"),\n                oto_entries=oto_entries,\n            ))\n\n        metadata = data.get(\"metadata\", {})\n        return cls(\n            project_name=data[\"project_name\"],\n            bpm=data[\"bpm\"],\n            reclist_path=data[\"reclist_path\"],\n            output_directory=data[\"output_directory\"],\n            recordings=recordings,\n            created_at=datetime.fromisoformat(metadata.get(\"created_at\", datetime.now().isoformat())),\n            last_modified=datetime.fromisoformat(metadata.get(\"last_modified\", datetime.now().isoformat())),\n            version=metadata.get(\"version\", \"1.0.0\"),\n        )\n\n    def validate(self) -&gt; List[str]:\n        \"\"\"Validate project data consistency.\n\n        Returns:\n            List of error messages, empty if valid.\n        \"\"\"\n        errors = []\n        if not self.project_name:\n            errors.append(\"Project name cannot be empty\")\n        if self.bpm &lt; 40 or self.bpm &gt; 300:\n            errors.append(f\"Invalid BPM: {self.bpm}\")\n\n        # Check integrity of recordings\n        for i, rec in enumerate(self.recordings):\n            if not rec.filename:\n                errors.append(f\"Recording at index {i} has no filename\")\n            if rec.duration_ms &lt; 0:\n                errors.append(f\"Invalid duration for {rec.filename}\")\n\n        return errors\n</code></pre>"},{"location":"reference/core/#core.models.ProjectData.from_dict","title":"<code>from_dict(data)</code>  <code>classmethod</code>","text":"<p>Create ProjectData from dictionary with validation.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If required fields are missing.</p> Source code in <code>src/core/models.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict) -&gt; \"ProjectData\":\n    \"\"\"Create ProjectData from dictionary with validation.\n\n    Raises:\n         ValueError: If required fields are missing.\n    \"\"\"\n    required_fields = [\"project_name\", \"bpm\", \"reclist_path\", \"output_directory\"]\n    missing = [f for f in required_fields if f not in data]\n    if missing:\n        raise ValueError(f\"Missing required fields in project data: {', '.join(missing)}\")\n\n    recordings = []\n    for r in data.get(\"recordings\", []):\n        oto_entries = [\n            OtoEntry(\n                filename=r[\"filename\"],\n                alias=e[\"alias\"],\n                offset=e[\"offset\"],\n                consonant=e[\"consonant\"],\n                cutoff=e[\"cutoff\"],\n                preutter=e[\"preutter\"],\n                overlap=e[\"overlap\"],\n                comment=e.get(\"comment\", \"\"),\n            )\n            for e in r.get(\"oto_entries\", [])\n        ]\n        recordings.append(Recording(\n            line_index=r[\"line_index\"],\n            filename=r[\"filename\"],\n            status=RecordingStatus(r[\"status\"]),\n            duration_ms=r.get(\"duration_ms\", 0.0),\n            hash=r.get(\"hash\"),\n            oto_entries=oto_entries,\n        ))\n\n    metadata = data.get(\"metadata\", {})\n    return cls(\n        project_name=data[\"project_name\"],\n        bpm=data[\"bpm\"],\n        reclist_path=data[\"reclist_path\"],\n        output_directory=data[\"output_directory\"],\n        recordings=recordings,\n        created_at=datetime.fromisoformat(metadata.get(\"created_at\", datetime.now().isoformat())),\n        last_modified=datetime.fromisoformat(metadata.get(\"last_modified\", datetime.now().isoformat())),\n        version=metadata.get(\"version\", \"1.0.0\"),\n    )\n</code></pre>"},{"location":"reference/core/#core.models.ProjectData.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert to dictionary for JSON serialization.</p> Source code in <code>src/core/models.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"Convert to dictionary for JSON serialization.\"\"\"\n    return {\n        \"project_name\": self.project_name,\n        \"bpm\": self.bpm,\n        \"reclist_path\": self.reclist_path,\n        \"output_directory\": self.output_directory,\n        \"recordings\": [\n            {\n                \"line_index\": r.line_index,\n                \"filename\": r.filename,\n                \"status\": r.status.value,\n                \"duration_ms\": r.duration_ms,\n                \"hash\": r.hash,\n                \"oto_entries\": [\n                    {\n                        \"alias\": e.alias,\n                        \"offset\": e.offset,\n                        \"consonant\": e.consonant,\n                        \"cutoff\": e.cutoff,\n                        \"preutter\": e.preutter,\n                        \"overlap\": e.overlap,\n                        \"comment\": e.comment,\n                    }\n                    for e in r.oto_entries\n                ],\n            }\n            for r in self.recordings\n        ],\n        \"metadata\": {\n            \"created_at\": self.created_at.isoformat(),\n            \"last_modified\": self.last_modified.isoformat(),\n            \"version\": self.version,\n        },\n    }\n</code></pre>"},{"location":"reference/core/#core.models.ProjectData.validate","title":"<code>validate()</code>","text":"<p>Validate project data consistency.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of error messages, empty if valid.</p> Source code in <code>src/core/models.py</code> <pre><code>def validate(self) -&gt; List[str]:\n    \"\"\"Validate project data consistency.\n\n    Returns:\n        List of error messages, empty if valid.\n    \"\"\"\n    errors = []\n    if not self.project_name:\n        errors.append(\"Project name cannot be empty\")\n    if self.bpm &lt; 40 or self.bpm &gt; 300:\n        errors.append(f\"Invalid BPM: {self.bpm}\")\n\n    # Check integrity of recordings\n    for i, rec in enumerate(self.recordings):\n        if not rec.filename:\n            errors.append(f\"Recording at index {i} has no filename\")\n        if rec.duration_ms &lt; 0:\n            errors.append(f\"Invalid duration for {rec.filename}\")\n\n    return errors\n</code></pre>"},{"location":"reference/core/#core.models.Recording","title":"<code>Recording</code>  <code>dataclass</code>","text":"<p>Represents a single recording with its oto entries.</p> Source code in <code>src/core/models.py</code> <pre><code>@dataclass\nclass Recording:\n    \"\"\"Represents a single recording with its oto entries.\"\"\"\n    line_index: int\n    filename: str\n    status: RecordingStatus = RecordingStatus.PENDING\n    duration_ms: float = 0.0\n    hash: Optional[str] = None\n    oto_entries: List[OtoEntry] = field(default_factory=list)\n</code></pre>"},{"location":"reference/core/#core.models.RecordingStatus","title":"<code>RecordingStatus</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Status of a recording line.</p> Source code in <code>src/core/models.py</code> <pre><code>class RecordingStatus(Enum):\n    \"\"\"Status of a recording line.\"\"\"\n    PENDING = \"pending\"\n    RECORDED = \"recorded\"\n    VALIDATED = \"validated\"\n</code></pre>"},{"location":"reference/ui/","title":"Referencia UI","text":"<p>Documentaci\u00f3n autogenerada de los componentes de interfaz.</p> <p>Main Window - Application container.</p> <p>Central widget that hosts all other UI components. Based on Section 9.2 layout specification.</p> <p>Reclist Widget - List of phonetic lines to record.</p> <p>Displays all lines from the loaded reclist with status indicators. Based on Section 9.2 ReclistWidget specification.</p> <p>Recorder Widget - Recording interface with metronome.</p> <p>Visual and audio metronome for synchronized recording. Based on Section 9.3 RecorderWidget specification.</p> <p>Editor Widget - Visual parameter editor wrapper.</p> <p>Holds the WaveformCanvas and navigation controls.</p>"},{"location":"reference/ui/#ui.main_window.MainWindow","title":"<code>MainWindow</code>","text":"<p>               Bases: <code>QMainWindow</code></p> <p>Main application window.</p> <p>Layout: \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 VocalParam v1.0.0-proto    [Archivo][Proyecto] [Ayuda]\u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502 \u2502  \u2502 RECLIST  \u2502  \u2502   RECORDER / EDITOR SEQ            \u2502  \u2502 \u2502  \u2502 [70 ln]  \u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502  \u2502 \u2502  \u2502          \u2502  \u2502  \u2502       Visual Editor          \u2502  \u2502  \u2502 \u2502  \u2502          \u2502  \u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524  \u2502  \u2502 \u2502  \u2502          \u2502  \u2502  \u2502      Parameter Table         \u2502  \u2502  \u2502 \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 Status: Ready | BPM: 120 | Project: [None]            \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518</p> Source code in <code>src/ui/main_window.py</code> <pre><code>class MainWindow(QMainWindow):\n    \"\"\"Main application window.\n\n    Layout:\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 VocalParam v1.0.0-proto    [Archivo] [Proyecto] [Ayuda]\u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n    \u2502  \u2502 RECLIST  \u2502  \u2502   RECORDER / EDITOR SEQ            \u2502  \u2502\n    \u2502  \u2502 [70 ln]  \u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502  \u2502\n    \u2502  \u2502          \u2502  \u2502  \u2502       Visual Editor          \u2502  \u2502  \u2502\n    \u2502  \u2502          \u2502  \u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524  \u2502  \u2502\n    \u2502  \u2502          \u2502  \u2502  \u2502      Parameter Table         \u2502  \u2502  \u2502\n    \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2502 Status: Ready | BPM: 120 | Project: [None]            \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self.setWindowTitle(\"VocalParam v1.0.0-prototype\")\n        self.setMinimumSize(1200, 800)\n\n        self._current_project: ProjectData = None\n        self._current_project_path = None\n        self._current_line: PhoneticLine = None\n        self._current_bpm = 120\n        self.audio_engine = AudioEngine()\n        self.resource_manager = ResourceManager()\n        self.oto_generator = OtoGenerator(self._current_bpm)\n\n        # Initialize Database\n        try:\n            self.db = AppDatabase()\n            self._load_recent_projects()\n        except Exception as e:\n            logger.error(f\"Failed to initialize database: {e}\")\n            self.db = None\n\n        self._setup_ui()\n\n        # Initialize Controller\n        self.editor_controller = EditorController(self.editor_widget, self.parameter_table)\n\n        self._setup_menu()\n        self._setup_statusbar()\n        self._setup_connections()\n        self._apply_dark_theme()\n\n        logger.info(\"MainWindow initialized\")\n\n    def _setup_ui(self):\n        \"\"\"Setup main UI layout.\"\"\"\n        central_widget = QWidget()\n        self.setCentralWidget(central_widget)\n\n        layout = QHBoxLayout(central_widget)\n        layout.setContentsMargins(10, 10, 10, 10)\n        layout.setSpacing(10)\n\n        # Create splitter for resizable panels\n        splitter = QSplitter(Qt.Orientation.Horizontal)\n\n        # Left panel: Reclist\n        self.reclist_widget = ReclistWidget()\n        splitter.addWidget(self.reclist_widget)\n\n        # Right panel: Content area using QStackedWidget\n        self.content_stack = QStackedWidget()\n\n        # 0: Placeholder\n        self.placeholder_widget = QWidget()\n        placeholder_layout = QVBoxLayout(self.placeholder_widget)\n        placeholder_label = QLabel(\"Cargue una reclist para comenzar\")\n        placeholder_label.setAlignment(Qt.AlignmentFlag.AlignCenter)\n        placeholder_label.setStyleSheet(f\"color: {COLORS['text_secondary']}; font-size: 18px;\")\n        placeholder_layout.addWidget(placeholder_label)\n        self.content_stack.addWidget(self.placeholder_widget)\n\n        # 1: Recorder\n        self.recorder_widget = RecorderWidget(self.audio_engine)\n        self.content_stack.addWidget(self.recorder_widget)\n\n        # 2: Editor Split View (Visual + Table)\n        editor_container = QWidget()\n        editor_layout = QVBoxLayout(editor_container)\n        editor_layout.setContentsMargins(0, 0, 0, 0)\n\n        editor_splitter = QSplitter(Qt.Orientation.Vertical)\n\n        self.editor_widget = EditorWidget()\n        self.parameter_table = ParameterTableWidget()\n\n        editor_splitter.addWidget(self.editor_widget)\n        editor_splitter.addWidget(self.parameter_table)\n        editor_splitter.setSizes([500, 200]) # Favor visual editor\n\n        editor_layout.addWidget(editor_splitter)\n        self.content_stack.addWidget(editor_container)\n\n        splitter.addWidget(self.content_stack)\n\n        # Set initial sizes (25% / 75%)\n        splitter.setSizes([300, 900])\n\n        layout.addWidget(splitter)\n\n    def _setup_connections(self):\n        \"\"\"Connect signals and slots.\"\"\"\n        self.reclist_widget.line_selected.connect(self._on_line_selected)\n        self.recorder_widget.recording_stopped.connect(self._on_recording_stopped)\n\n        # Connection from Editor Table to loading audio\n        self.parameter_table.row_selected.connect(self._on_editor_row_selected)\n\n        # New: Auto-save on edits (non-explicit)\n        self.editor_controller.project_updated.connect(lambda: self._on_save_project(explicit=False))\n\n        # New: Direct Editor Access\n        self.btn_goto_editor = QPushButton(\"\u270f Editor Global\")\n        self.btn_goto_editor.setStyleSheet(f\"background-color: {COLORS['accent_primary']}; font-weight: bold; padding: 5px;\")\n        self.btn_goto_editor.clicked.connect(self._on_goto_editor)\n        self.reclist_widget.layout().addWidget(self.btn_goto_editor)\n\n    def _on_line_selected(self, index, line):\n        \"\"\"Handle line selection from reclist.\"\"\"\n        logger.info(f\"Line selected: {line.raw_text}\")\n        self._current_line = line\n        self.recorder_widget.set_line(line)\n        self.recorder_widget.set_bpm(self._current_bpm)\n\n        # Set default output path for recorded audio if project exists\n        if self._current_project:\n            project_dir = self._current_project_path.parent if self._current_project_path else Path(\".\")\n            output_dir = Path(self._current_project.output_directory)\n            if not output_dir.is_absolute():\n                output_dir = project_dir / output_dir\n            self.recorder_widget.path_edit.setText(str(output_dir))\n\n        self.content_stack.setCurrentIndex(1)  # Show recorder\n\n    def _on_recording_stopped(self, audio_data):\n        \"\"\"Handle recording completion.\"\"\"\n        if audio_data is not None and self._current_line:\n             logger.info(f\"Received audio data for line: {self._current_line.raw_text}\")\n\n             # 1. Check for Project\n             if not self._current_project:\n                 res = QMessageBox.question(self, \"Proyecto Requerido\", \n                     \"La grabaci\u00f3n se ha guardado localmente, pero no hay un proyecto abierto para organizar la metadata.\\n\\n\"\n                     \"\u00bfDesea crear un proyecto nuevo ahora?\",\n                     QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No)\n                 if res == QMessageBox.StandardButton.Yes:\n                     self._on_new_project()\n\n             # 2. Update Project (if it was created or already existed)\n             recording = None\n             if self._current_project:\n                 recording = self._update_project_recording(self._current_line, audio_data)\n\n             # 2. Generate Initial OTO\n             # Use the first segment as the alias for now (prototype limitation)\n             # TODO: Handle multi-segment logic\n             alias = self._current_line.segments[0] if self._current_line.segments else self._current_line.raw_text\n\n             entry = self.oto_generator.generate_oto(\n                 filename=f\"{self._current_line.raw_text}.wav\",\n                 audio_data=audio_data,\n                 alias=alias,\n                 count_in_beats=self.recorder_widget.COUNT_IN_BEATS\n             )\n\n             # Link entry to recording for persistence\n             if recording:\n                 # Check if this alias already exists in this recording\n                 existing_entry = next((e for e in recording.oto_entries if e.alias == entry.alias), None)\n                 if existing_entry:\n                     # Update existing\n                     existing_entry.offset = entry.offset\n                     existing_entry.consonant = entry.consonant\n                     existing_entry.cutoff = entry.cutoff\n                     existing_entry.preutter = entry.preutter\n                     existing_entry.overlap = entry.overlap\n                     entry = existing_entry # Use the reference in the project\n                 else:\n                     recording.oto_entries.append(entry)\n\n             # 3. Load into Editor\n             self.editor_controller.load_entry(\n                 entry, \n                 audio_data, \n                 self.audio_engine._sample_rate\n             )\n\n             # 4. Switch View\n             self.content_stack.setCurrentIndex(2) # Show Editor Container\n\n             # Refresh the GLOBAL table to show all recorded samples\n             self._on_goto_editor() \n\n             self.statusbar.showMessage(f\"Grabaci\u00f3n '{alias}' lista para editar.\", 3000)\n\n    def _on_goto_editor(self):\n        \"\"\"Switch to editor view manually.\"\"\"\n        # Load all project recordings into the table if project exists\n        if self._current_project:\n            all_entries = []\n            for rec in self._current_project.recordings:\n                all_entries.extend(rec.oto_entries)\n            self.parameter_table.set_entries(all_entries)\n            self.statusbar.showMessage(\"Cargadas todas las grabaciones en el Editor.\", 3000)\n        else:\n            self.parameter_table.set_entries([])\n            self.statusbar.showMessage(\"Abierto Editor (Sin Proyecto)\", 3000)\n\n        self.content_stack.setCurrentIndex(2)\n\n    def _on_editor_row_selected(self, entry: OtoEntry):\n        \"\"\"Handle selection of a row in the global parameter table.\"\"\"\n        if not self._current_project:\n            return\n\n        # Find the recording that contains this entry\n        recording = next((r for r in self._current_project.recordings if entry in r.oto_entries), None)\n        if not recording:\n            logger.warning(f\"No recording found for alias: {entry.alias}\")\n            return\n\n        # Load audio file\n        project_dir = self._current_project_path.parent if self._current_project_path else Path(\".\")\n        output_dir = Path(self._current_project.output_directory)\n        if not output_dir.is_absolute():\n            output_dir = project_dir / output_dir\n\n        wav_path = output_dir / recording.filename\n\n        if wav_path.exists():\n            try:\n                audio_data, sr = self.audio_engine.load_wav(str(wav_path))\n                self.editor_controller.load_entry(entry, audio_data, sr)\n                self.statusbar.showMessage(f\"Cargado: {entry.alias}\", 2000)\n            except Exception as e:\n                logger.error(f\"Failed to load audio for editor: {e}\")\n                self.statusbar.showMessage(f\"Error al cargar audio: {recording.filename}\", 3000)\n        else:\n            self.statusbar.showMessage(f\"Archivo no encontrado: {recording.filename}\", 3000)\n\n    def _update_project_recording(self, line, audio_data):\n        \"\"\"Update or add a recording entry to the current project.\"\"\"\n        if not self._current_project:\n            return\n\n        wav_name = f\"{line.raw_text}.wav\"\n        save_path = Path(self.recorder_widget.path_edit.text()) / wav_name\n\n        # Calculate hash for integrity\n        try:\n            # We hash the file after it's saved by RecorderWidget\n            # (Wait, actually RecorderWidget._on_accept saves it)\n            # Let's verify it exists\n            if save_path.exists():\n                file_hash = self.resource_manager.calculate_checksum(save_path)\n\n                from core.models import Recording, RecordingStatus\n                # Find existing or create new\n                existing = next((r for r in self._current_project.recordings if r.line_index == line.index), None)\n\n                if existing:\n                    existing.filename = wav_name\n                    existing.status = RecordingStatus.RECORDED\n                    existing.duration_ms = len(audio_data) / self.audio_engine._active_sr * 1000\n                    existing.hash = file_hash\n                else:\n                    new_rec = Recording(\n                        line_index=line.index,\n                        filename=wav_name,\n                        status=RecordingStatus.RECORDED,\n                        duration_ms=len(audio_data) / self.audio_engine._active_sr * 1000,\n                        hash=file_hash\n                    )\n                    self._current_project.recordings.append(new_rec)\n\n                # Update Reclist UI\n                self.reclist_widget.set_line_status(line.index, RecordingStatus.RECORDED)\n\n                logger.info(f\"Project updated with recording: {wav_name} (Hash: {file_hash[:8]}...)\")\n                return existing or new_rec\n        except Exception as e:\n            logger.error(f\"Failed to update project recording: {e}\")\n        return None\n\n    def _setup_menu(self):\n        \"\"\"Setup menu bar.\"\"\"\n        menubar = self.menuBar()\n\n        # File menu\n        file_menu = menubar.addMenu(\"&amp;Archivo\")\n\n        new_action = QAction(\"&amp;Nuevo Proyecto\", self)\n        new_action.setShortcut(QKeySequence.StandardKey.New)\n        new_action.triggered.connect(self._on_new_project)\n        file_menu.addAction(new_action)\n\n        open_action = QAction(\"&amp;Abrir Proyecto\", self)\n        open_action.setShortcut(QKeySequence.StandardKey.Open)\n        open_action.triggered.connect(self._on_open_project)\n        file_menu.addAction(open_action)\n\n        file_menu.addSeparator()\n\n        load_reclist = QAction(\"Cargar &amp;Reclist...\", self)\n        load_reclist.setShortcut(\"Ctrl+R\")\n        load_reclist.triggered.connect(self._on_load_reclist)\n        file_menu.addAction(load_reclist)\n\n        file_menu.addSeparator()\n\n        save_action = QAction(\"&amp;Guardar\", self)\n        save_action.setShortcut(QKeySequence.StandardKey.Save)\n        save_action.triggered.connect(self._on_save_project)\n        file_menu.addAction(save_action)\n\n        export_action = QAction(\"&amp;Exportar Voicebank...\", self)\n        export_action.setShortcut(\"Ctrl+E\")\n        export_action.triggered.connect(self._on_export)\n        file_menu.addAction(export_action)\n\n        file_menu.addSeparator()\n\n        exit_action = QAction(\"&amp;Salir\", self)\n        exit_action.setShortcut(QKeySequence.StandardKey.Quit)\n        exit_action.triggered.connect(self.close)\n        file_menu.addAction(exit_action)\n\n        # Project menu\n        project_menu = menubar.addMenu(\"&amp;Proyecto\")\n\n        generate_oto = QAction(\"&amp;Generar oto.ini\", self)\n        generate_oto.setShortcut(\"Ctrl+G\")\n        generate_oto.triggered.connect(self._on_generate_oto)\n        project_menu.addAction(generate_oto)\n\n        project_menu.addSeparator()\n\n        audio_setup = QAction(\"\u2699 Configuraci\u00f3n de Audio\", self)\n        audio_setup.triggered.connect(self._on_audio_settings)\n        project_menu.addAction(audio_setup)\n\n        # Help menu\n        help_menu = menubar.addMenu(\"A&amp;yuda\")\n\n        about_action = QAction(\"&amp;Acerca de\", self)\n        about_action.triggered.connect(self._on_about)\n        help_menu.addAction(about_action)\n\n    def _setup_statusbar(self):\n        \"\"\"Setup status bar.\"\"\"\n        self.statusbar = QStatusBar()\n        self.setStatusBar(self.statusbar)\n\n        self.status_label = QLabel(\"Listo\")\n        self.bpm_label = QLabel(f\"BPM: {self._current_bpm}\")\n        self.project_label = QLabel(\"Proyecto: [Ninguno]\")\n\n        self.statusbar.addWidget(self.status_label, 1)\n        self.statusbar.addPermanentWidget(self.bpm_label)\n        self.statusbar.addPermanentWidget(self.project_label)\n\n    def _apply_dark_theme(self):\n        \"\"\"Apply dark mode theme from design spec.\"\"\"\n        self.setStyleSheet(f\"\"\"\n            QMainWindow {{\n                background-color: {COLORS['background']};\n            }}\n            QWidget {{\n                background-color: {COLORS['background']};\n                color: {COLORS['text_primary']};\n            }}\n            QMenuBar {{\n                background-color: #2D2D2D;\n                color: {COLORS['text_primary']};\n            }}\n            QMenuBar::item:selected {{\n                background-color: #3D3D3D;\n            }}\n            QMenu {{\n                background-color: #2D2D2D;\n                color: {COLORS['text_primary']};\n            }}\n            QMenu::item:selected {{\n                background-color: #3D3D3D;\n            }}\n            QStatusBar {{\n                background-color: #2D2D2D;\n                color: {COLORS['text_secondary']};\n            }}\n            QSplitter::handle {{\n                background-color: #3D3D3D;\n            }}\n        \"\"\")\n\n    def _on_new_project(self):\n        \"\"\"Handle new project action.\"\"\"\n        dialog = ProjectDialog(self)\n        if dialog.exec() == ProjectDialog.DialogCode.Accepted:\n            data = dialog.get_data()\n            if not data: return\n\n            # Create Project Model\n            project = ProjectData(\n                project_name=data[\"name\"],\n                bpm=data[\"bpm\"],\n                reclist_path=data[\"reclist\"],\n                output_directory=data[\"output\"]\n            )\n\n            try:\n                # Save immediately\n                ProjectRepository.save_project(project, data[\"save_path\"])\n                self._current_project_path = Path(data[\"save_path\"])\n                self._load_project_ui(project)\n\n                # Setup Resource Manager\n                self.resource_manager.set_project_root(self._current_project_path.parent)\n\n                QMessageBox.information(self, \"Proyecto Creado\", f\"El proyecto '{project.project_name}' ha sido creado exitosamente.\")\n            except Exception as e:\n                logger.error(f\"Failed to create project: {e}\")\n                QMessageBox.critical(self, \"Error\", f\"No se pudo crear el proyecto:\\n{e}\")\n\n    def _on_open_project(self):\n        \"\"\"Handle open project action.\"\"\"\n        filepath, _ = QFileDialog.getOpenFileName(\n            self, \"Abrir Proyecto\", \"\",\n            \"Proyectos VocalParam (*.vocalproj);;Todos los archivos (*)\"\n        )\n        if filepath:\n            filepath = Path(filepath)\n            logger.info(f\"Opening project: {filepath}\")\n\n            # Check locking\n            if not self.resource_manager.create_lock_file(filepath):\n                QMessageBox.warning(self, \"Proyecto Bloqueado\", \n                                  \"El proyecto ya parece estar abierto en otra instancia o est\u00e1 bloqueado.\")\n                return\n\n            try:\n                project = ProjectRepository.load_project(filepath)\n                self._current_project_path = filepath\n\n                # Verify resources and Integrity\n                self._verify_project_resources(project, filepath.parent)\n                self._load_project_ui(project)\n\n                # Start background integrity checks\n                self.resource_manager.set_project_root(filepath.parent)\n                self.resource_manager.start_background_scrubbing()\n\n                self.statusbar.showMessage(f\"Proyecto cargado: {project.project_name}\", 3000)\n            except PersistenceError as e:\n                self.resource_manager.release_lock(filepath)\n                QMessageBox.critical(self, \"Error al abrir\", str(e))\n                logger.error(f\"Error opening project: {e}\")\n\n    def _on_load_reclist(self):\n        \"\"\"Handle load reclist action.\"\"\"\n        filepath, _ = QFileDialog.getOpenFileName(\n            self, \"Cargar Reclist\", \"\",\n            \"Archivos de texto (*.txt);;Todos los archivos (*)\"\n        )\n        if filepath:\n            logger.info(f\"Loading reclist: {filepath}\")\n            self.reclist_widget.load_reclist(filepath)\n            self.statusbar.showMessage(f\"Reclist cargada: {filepath}\", 3000)\n\n    def _load_recent_projects(self):\n        \"\"\"Update recent projects menu (placeholder for full implementation).\"\"\"\n        if not self.db:\n            return\n        # In a real app, this would populate a submenu. \n        # For now, we just log it to verify DB connectivity.\n        recent = self.db.get_recent_projects(limit=5)\n        logger.info(f\"Loaded {len(recent)} recent projects from DB\")\n\n    def _on_save_project(self, explicit=True):\n        \"\"\"Handle save project action.\n\n        Args:\n            explicit: If True, show dialogs and errors. If False (auto-save), be silent \n                     unless a critical error occurs and only if a path is already set.\n        \"\"\"\n        if not self._current_project:\n            if explicit:\n                QMessageBox.warning(self, \"Guardar\", \"Primero debe crear o abrir un proyecto.\")\n            return\n\n        # Get existing path\n        filepath = self._current_project_path\n\n        # If no path and user clicked Save, ask for one\n        if not filepath and explicit:\n            filepath, _ = QFileDialog.getSaveFileName(\n                self, \"Guardar Proyecto\", \"\",\n                \"Proyectos VocalParam (*.vocalproj)\"\n            )\n            if filepath:\n                self._current_project_path = Path(filepath)\n            else:\n                return # User cancelled\n\n        # Only proceed if we have a path\n        if self._current_project_path:\n            try:\n                # Update metadata\n                self._current_project.last_modified = datetime.now()\n\n                ProjectRepository.save_project(self._current_project, self._current_project_path)\n\n                if explicit:\n                    self.statusbar.showMessage(\"Proyecto guardado correctamente\", 3000)\n                else:\n                    self.statusbar.showMessage(\"Proyecto auto-guardado\", 1000)\n            except PersistenceError as e:\n                logger.error(f\"Error saving project: {e}\")\n                if explicit:\n                    QMessageBox.critical(self, \"Error al guardar\", str(e))\n\n    def _verify_project_resources(self, project: ProjectData, project_dir: Path):\n        \"\"\"Check if all recordings exist and verify integrity.\"\"\"\n        missing = []\n        corrupted = []\n\n        output_dir = Path(project.output_directory)\n        if not output_dir.is_absolute():\n            output_dir = project_dir / output_dir\n\n        for rec in project.recordings:\n            wav_path = output_dir / rec.filename\n            if not wav_path.exists():\n                # Try smart relinking\n                recovered = self.resource_manager.find_missing_resource(wav_path, [project_dir])\n                if recovered:\n                    rec.filename = os.path.relpath(recovered, output_dir)\n                    logger.info(f\"Relinked {rec.filename} to {recovered}\")\n                else:\n                    missing.append(rec.filename)\n            elif rec.hash:\n                # Verify integrity\n                current_hash = self.resource_manager.calculate_checksum(wav_path)\n                if current_hash != rec.hash:\n                    corrupted.append(rec.filename)\n\n        if missing or corrupted:\n            msg = \"Problemas detectados en los recursos:\\n\"\n            if missing:\n                msg += f\"\\nFaltantes ({len(missing)}):\\n\" + \"\\n\".join(missing[:5])\n                if len(missing) &gt; 5: msg += \"\\n...\"\n            if corrupted:\n                msg += f\"\\nCorruptos/Modificados ({len(corrupted)}):\\n\" + \"\\n\".join(corrupted[:5])\n                if len(corrupted) &gt; 5: msg += \"\\n...\"\n\n            QMessageBox.warning(self, \"Integridad de Recursos\", msg)\n\n    def _load_project_ui(self, project: ProjectData):\n        \"\"\"Update UI with project data.\"\"\"\n        self._current_project = project\n        # Note: self._current_project_path must be set before calling this \n        # as ProjectData doesn't store its own file path.\n        self._current_bpm = project.bpm\n\n        self.project_label.setText(f\"Proyecto: {project.project_name}\")\n        self.bpm_label.setText(f\"BPM: {project.bpm}\")\n\n        # Load reclist if path exists\n        if project.reclist_path:\n             self.reclist_widget.load_reclist(project.reclist_path)\n\n        # Load recording statuses into Reclist UI\n        from core.models import RecordingStatus\n        for rec in project.recordings:\n            self.reclist_widget.set_line_status(rec.line_index, rec.status)\n\n        self.statusbar.showMessage(f\"Proyecto {project.project_name} cargado\", 3000)\n        \"\"\"Load recent projects specific logic (placeholder for menu update).\"\"\"\n        # This would update the \"Open Recent\" menu\n        pass\n\n    def _on_export(self):\n        \"\"\"Handle export action.\"\"\"\n        folder = QFileDialog.getExistingDirectory(\n            self, \"Seleccionar carpeta de exportaci\u00f3n\"\n        )\n        if folder:\n            logger.info(f\"Exporting to: {folder}\")\n            # TODO: Implement export\n            self.statusbar.showMessage(f\"Exportado a: {folder}\", 3000)\n\n    def _on_generate_oto(self):\n        \"\"\"Handle generate oto.ini action.\"\"\"\n        logger.info(\"Generate oto.ini requested\")\n        # TODO: Implement oto generation\n        self.statusbar.showMessage(\"Generando oto.ini...\", 3000)\n\n    def _on_audio_settings(self):\n        \"\"\"Show audio hardware configuration and apply settings.\"\"\"\n        dialog = AudioSettingsDialog(self.audio_engine, self)\n        if dialog.exec() == AudioSettingsDialog.DialogCode.Accepted:\n            input_idx, output_idx, sr = dialog.get_selected_devices()\n            self.audio_engine.set_devices(input_idx, output_idx)\n            self.audio_engine.set_sample_rate(sr) # This also regenerates clicks\n            self.audio_engine.save_config() \n            self.statusbar.showMessage(f\"Configuraci\u00f3n actualizada: {sr}Hz\", 3000)\n\n    def closeEvent(self, event):\n        \"\"\"Cleanup on close.\"\"\"\n        self.resource_manager.stop_background_scrubbing()\n        if self._current_project_path:\n            self.resource_manager.release_lock(Path(self._current_project_path))\n        if hasattr(self, 'db') and self.db:\n            self.db.close()\n        super().closeEvent(event)\n\n    def _on_about(self):\n        \"\"\"Show about dialog.\"\"\"\n        QMessageBox.about(\n            self,\n            \"Acerca de VocalParam\",\n            \"&lt;h2&gt;VocalParam v1.0.0-prototype&lt;/h2&gt;\"\n            \"&lt;p&gt;Sistema Unificado de Grabaci\u00f3n y Configuraci\u00f3n de Voicebanks&lt;/p&gt;\"\n            \"&lt;p&gt;Licencia: MIT Open Source&lt;/p&gt;\"\n            \"&lt;p&gt;&lt;a href='https://github.com/org/vocalparam'&gt;GitHub&lt;/a&gt;&lt;/p&gt;\"\n        )\n</code></pre>"},{"location":"reference/ui/#ui.main_window.MainWindow.closeEvent","title":"<code>closeEvent(event)</code>","text":"<p>Cleanup on close.</p> Source code in <code>src/ui/main_window.py</code> <pre><code>def closeEvent(self, event):\n    \"\"\"Cleanup on close.\"\"\"\n    self.resource_manager.stop_background_scrubbing()\n    if self._current_project_path:\n        self.resource_manager.release_lock(Path(self._current_project_path))\n    if hasattr(self, 'db') and self.db:\n        self.db.close()\n    super().closeEvent(event)\n</code></pre>"},{"location":"reference/ui/#ui.reclist_widget.ReclistWidget","title":"<code>ReclistWidget</code>","text":"<p>               Bases: <code>QWidget</code></p> <p>Widget displaying list of reclist lines with status.</p> Signals <p>line_selected: Emitted when a line is selected (index, PhoneticLine)</p> Source code in <code>src/ui/reclist_widget.py</code> <pre><code>class ReclistWidget(QWidget):\n    \"\"\"Widget displaying list of reclist lines with status.\n\n    Signals:\n        line_selected: Emitted when a line is selected (index, PhoneticLine)\n    \"\"\"\n\n    line_selected = pyqtSignal(int, object)  # index, PhoneticLine\n\n    def __init__(self, parent=None):\n        super().__init__(parent)\n        self.parser = ReclistParser()\n        self._lines: List[PhoneticLine] = []\n        self._statuses: dict[int, RecordingStatus] = {}\n\n        self._setup_ui()\n\n    def _setup_ui(self):\n        \"\"\"Setup widget UI.\"\"\"\n        layout = QVBoxLayout(self)\n        layout.setContentsMargins(5, 5, 5, 5)\n        layout.setSpacing(5)\n\n        # Header\n        header = QLabel(\"RECLIST\")\n        header.setStyleSheet(f\"\"\"\n            font-weight: bold;\n            font-size: 14px;\n            color: {COLORS['text_primary']};\n            padding: 5px;\n        \"\"\")\n        layout.addWidget(header)\n\n        # Line count label\n        self.count_label = QLabel(\"0 l\u00edneas\")\n        self.count_label.setStyleSheet(f\"color: {COLORS['text_secondary']};\")\n        layout.addWidget(self.count_label)\n\n        # List widget\n        self.list_widget = QListWidget()\n        self.list_widget.setStyleSheet(f\"\"\"\n            QListWidget {{\n                background-color: #252525;\n                border: 1px solid #3D3D3D;\n                border-radius: 4px;\n            }}\n            QListWidget::item {{\n                padding: 8px;\n                border-bottom: 1px solid #3D3D3D;\n            }}\n            QListWidget::item:selected {{\n                background-color: #3D3D3D;\n            }}\n            QListWidget::item:hover {{\n                background-color: #353535;\n            }}\n        \"\"\")\n        self.list_widget.itemClicked.connect(self._on_item_clicked)\n        self.list_widget.itemDoubleClicked.connect(self._on_item_double_clicked)\n        layout.addWidget(self.list_widget)\n\n        # Buttons\n        button_layout = QHBoxLayout()\n\n        self.load_btn = QPushButton(\"Cargar...\")\n        self.load_btn.setStyleSheet(self._button_style())\n        self.load_btn.clicked.connect(self._on_load_clicked)\n        button_layout.addWidget(self.load_btn)\n\n        layout.addLayout(button_layout)\n\n    def _button_style(self) -&gt; str:\n        \"\"\"Return button stylesheet.\"\"\"\n        return f\"\"\"\n            QPushButton {{\n                background-color: #3D3D3D;\n                color: {COLORS['text_primary']};\n                border: none;\n                border-radius: 4px;\n                padding: 8px 16px;\n            }}\n            QPushButton:hover {{\n                background-color: #4D4D4D;\n            }}\n            QPushButton:pressed {{\n                background-color: #2D2D2D;\n            }}\n        \"\"\"\n\n    def load_reclist(self, filepath: str) -&gt; bool:\n        \"\"\"Load and parse a reclist file.\n\n        Args:\n            filepath: Path to reclist .txt file\n\n        Returns:\n            True if loaded successfully\n        \"\"\"\n        try:\n            self._lines = self.parser.parse_file(filepath)\n            self._statuses = {line.index: RecordingStatus.PENDING for line in self._lines}\n            self._populate_list()\n            logger.info(f\"Loaded reclist with {len(self._lines)} lines\")\n            return True\n        except ReclistParseError as e:\n            logger.error(f\"Failed to parse reclist: {e}\")\n            return False\n        except FileNotFoundError as e:\n            logger.error(f\"Reclist file not found: {e}\")\n            return False\n\n    def _populate_list(self):\n        \"\"\"Populate list widget with loaded lines.\"\"\"\n        self.list_widget.clear()\n\n        for line in self._lines:\n            status = self._statuses.get(line.index, RecordingStatus.PENDING)\n            item = QListWidgetItem(self._format_line(line, status))\n            item.setData(Qt.ItemDataRole.UserRole, line.index)\n\n            # Color based on status\n            if status == RecordingStatus.RECORDED:\n                item.setForeground(QBrush(QColor(COLORS['success'])))\n            elif status == RecordingStatus.VALIDATED:\n                item.setForeground(QBrush(QColor(\"#50FA7B\")))  # Brighter green\n            else:\n                item.setForeground(QBrush(QColor(COLORS['text_secondary'])))\n\n            self.list_widget.addItem(item)\n\n        self.count_label.setText(f\"{len(self._lines)} l\u00edneas\")\n\n    def _format_line(self, line: PhoneticLine, status: RecordingStatus) -&gt; str:\n        \"\"\"Format line for display.\"\"\"\n        status_icon = {\n            RecordingStatus.PENDING: \"\u2610\",\n            RecordingStatus.RECORDED: \"\u2611\",\n            RecordingStatus.VALIDATED: \"\u2713\"\n        }.get(status, \"\u2610\")\n\n        return f\"{status_icon} {line.index:03d} {line.raw_text}\"\n\n    def set_line_status(self, index: int, status: RecordingStatus):\n        \"\"\"Update status of a specific line.\n\n        Args:\n            index: Line index\n            status: New status\n        \"\"\"\n        self._statuses[index] = status\n        self._populate_list()  # Refresh display\n\n    def get_line(self, index: int) -&gt; Optional[PhoneticLine]:\n        \"\"\"Get PhoneticLine by index.\"\"\"\n        for line in self._lines:\n            if line.index == index:\n                return line\n        return None\n\n    def _on_item_clicked(self, item: QListWidgetItem):\n        \"\"\"Handle item click.\"\"\"\n        index = item.data(Qt.ItemDataRole.UserRole)\n        line = self.get_line(index)\n        if line:\n            self.line_selected.emit(index, line)\n\n    def _on_item_double_clicked(self, item: QListWidgetItem):\n        \"\"\"Handle item double click - start recording.\"\"\"\n        # TODO: Trigger recording mode\n        pass\n\n    def _on_load_clicked(self):\n        \"\"\"Handle load button click.\"\"\"\n        from PyQt6.QtWidgets import QFileDialog\n        filepath, _ = QFileDialog.getOpenFileName(\n            self, \"Cargar Reclist\", \"\",\n            \"Archivos de texto (*.txt);;Todos los archivos (*)\"\n        )\n        if filepath:\n            self.load_reclist(filepath)\n</code></pre>"},{"location":"reference/ui/#ui.reclist_widget.ReclistWidget.get_line","title":"<code>get_line(index)</code>","text":"<p>Get PhoneticLine by index.</p> Source code in <code>src/ui/reclist_widget.py</code> <pre><code>def get_line(self, index: int) -&gt; Optional[PhoneticLine]:\n    \"\"\"Get PhoneticLine by index.\"\"\"\n    for line in self._lines:\n        if line.index == index:\n            return line\n    return None\n</code></pre>"},{"location":"reference/ui/#ui.reclist_widget.ReclistWidget.load_reclist","title":"<code>load_reclist(filepath)</code>","text":"<p>Load and parse a reclist file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to reclist .txt file</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if loaded successfully</p> Source code in <code>src/ui/reclist_widget.py</code> <pre><code>def load_reclist(self, filepath: str) -&gt; bool:\n    \"\"\"Load and parse a reclist file.\n\n    Args:\n        filepath: Path to reclist .txt file\n\n    Returns:\n        True if loaded successfully\n    \"\"\"\n    try:\n        self._lines = self.parser.parse_file(filepath)\n        self._statuses = {line.index: RecordingStatus.PENDING for line in self._lines}\n        self._populate_list()\n        logger.info(f\"Loaded reclist with {len(self._lines)} lines\")\n        return True\n    except ReclistParseError as e:\n        logger.error(f\"Failed to parse reclist: {e}\")\n        return False\n    except FileNotFoundError as e:\n        logger.error(f\"Reclist file not found: {e}\")\n        return False\n</code></pre>"},{"location":"reference/ui/#ui.reclist_widget.ReclistWidget.set_line_status","title":"<code>set_line_status(index, status)</code>","text":"<p>Update status of a specific line.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>Line index</p> required <code>status</code> <code>RecordingStatus</code> <p>New status</p> required Source code in <code>src/ui/reclist_widget.py</code> <pre><code>def set_line_status(self, index: int, status: RecordingStatus):\n    \"\"\"Update status of a specific line.\n\n    Args:\n        index: Line index\n        status: New status\n    \"\"\"\n    self._statuses[index] = status\n    self._populate_list()  # Refresh display\n</code></pre>"},{"location":"reference/ui/#ui.recorder_widget.MoraBox","title":"<code>MoraBox</code>","text":"<p>               Bases: <code>QWidget</code></p> <p>Single mora indicator box.</p> Source code in <code>src/ui/recorder_widget.py</code> <pre><code>class MoraBox(QWidget):\n    \"\"\"Single mora indicator box.\"\"\"\n\n    def __init__(self, text: str, parent=None):\n        super().__init__(parent)\n        self.text = text\n        self._active = False\n        self.setMinimumSize(60, 60)\n        self._setup_ui()\n\n    def _setup_ui(self):\n        layout = QVBoxLayout(self)\n        layout.setContentsMargins(5, 5, 5, 5)\n\n        self.label = QLabel(self.text)\n        self.label.setAlignment(Qt.AlignmentFlag.AlignCenter)\n        self.label.setStyleSheet(f\"\"\"\n            font-size: 16px;\n            font-weight: bold;\n            color: {COLORS['text_primary']};\n        \"\"\")\n        layout.addWidget(self.label)\n\n        self._update_style()\n\n    def set_active(self, active: bool):\n        \"\"\"Set whether this mora is currently active.\"\"\"\n        self._active = active\n        self._update_style()\n\n    def _update_style(self):\n        \"\"\"Update visual style based on state.\"\"\"\n        if self._active:\n            self.setStyleSheet(f\"\"\"\n                QWidget {{\n                    background-color: {COLORS['accent_recording']};\n                    border: 2px solid {COLORS['accent_recording']};\n                    border-radius: 8px;\n                }}\n            \"\"\")\n        else:\n            self.setStyleSheet(f\"\"\"\n                QWidget {{\n                    background-color: #2D2D2D;\n                    border: 2px solid #3D3D3D;\n                    border-radius: 8px;\n                }}\n            \"\"\")\n</code></pre>"},{"location":"reference/ui/#ui.recorder_widget.MoraBox.set_active","title":"<code>set_active(active)</code>","text":"<p>Set whether this mora is currently active.</p> Source code in <code>src/ui/recorder_widget.py</code> <pre><code>def set_active(self, active: bool):\n    \"\"\"Set whether this mora is currently active.\"\"\"\n    self._active = active\n    self._update_style()\n</code></pre>"},{"location":"reference/ui/#ui.recorder_widget.RecorderWidget","title":"<code>RecorderWidget</code>","text":"<p>               Bases: <code>QWidget</code></p> <p>Recording interface with visual metronome.</p> <p>Displays 7 mora boxes that highlight in sequence during recording.</p> Signals <p>recording_started: Emitted when recording begins recording_stopped: Emitted when recording ends (with audio data) recording_cancelled: Emitted when recording is cancelled</p> Source code in <code>src/ui/recorder_widget.py</code> <pre><code>class RecorderWidget(QWidget):\n    \"\"\"Recording interface with visual metronome.\n\n    Displays 7 mora boxes that highlight in sequence during recording.\n\n    Signals:\n        recording_started: Emitted when recording begins\n        recording_stopped: Emitted when recording ends (with audio data)\n        recording_cancelled: Emitted when recording is cancelled\n    \"\"\"\n\n    recording_started = pyqtSignal()\n    recording_stopped = pyqtSignal(object)  # audio data\n    recording_cancelled = pyqtSignal()\n\n    MIN_RECORDING_DURATION_MS = 4000\n    COUNT_IN_BEATS = 3\n\n    def __init__(self, audio_engine: AudioEngine, parent=None):\n        super().__init__(parent)\n        self.engine = audio_engine\n        self._bpm = DEFAULT_BPM\n        self._current_line: PhoneticLine = None\n        self._current_mora = 0\n        self._count_in_counter = 0 # Negative during count-in\n        self._is_recording = False\n        self._last_audio = None\n\n        # Determine default save path\n        project_root = Path(__file__).parent.parent.parent\n        self._dest_path = project_root / \"recordings\" / \"test_samples\"\n        self._dest_path.mkdir(parents=True, exist_ok=True)\n\n        self._setup_ui()\n        self._setup_timers()\n\n    def _setup_ui(self):\n        \"\"\"Setup widget UI.\"\"\"\n        layout = QVBoxLayout(self)\n        layout.setContentsMargins(20, 20, 20, 20)\n        layout.setSpacing(20)\n\n        # Title\n        self.title_label = QLabel(\"GRABANDO\")\n        self.title_label.setStyleSheet(f\"\"\"\n            font-size: 24px;\n            font-weight: bold;\n            color: {COLORS['text_secondary']};\n        \"\"\")\n        self.title_label.setAlignment(Qt.AlignmentFlag.AlignCenter)\n        layout.addWidget(self.title_label)\n\n        # Line text\n        self.line_label = QLabel(\"Seleccione una l\u00ednea para grabar\")\n        self.line_label.setStyleSheet(f\"\"\"\n            font-size: 18px;\n            color: {COLORS['text_secondary']};\n        \"\"\")\n        self.line_label.setAlignment(Qt.AlignmentFlag.AlignCenter)\n        layout.addWidget(self.line_label)\n\n        # Instruction\n        instruction = QLabel(\"Pronuncia cada s\u00edlaba al ritmo del metr\u00f3nomo:\")\n        instruction.setStyleSheet(f\"color: {COLORS['text_secondary']};\")\n        instruction.setAlignment(Qt.AlignmentFlag.AlignCenter)\n        layout.addWidget(instruction)\n\n        # Path Destination Selector\n        path_layout = QHBoxLayout()\n        path_label = QLabel(\"Destino:\")\n        path_label.setFixedWidth(50)\n        path_layout.addWidget(path_label)\n\n        self.path_edit = QLineEdit(str(self._dest_path))\n        self.path_edit.setStyleSheet(f\"\"\"\n            QLineEdit {{\n                background-color: #252525;\n                color: {COLORS['text_primary']};\n                border: 1px solid #3D3D3D;\n                border-radius: 4px;\n                padding: 5px;\n            }}\n        \"\"\")\n        self.path_edit.setReadOnly(True)\n        path_layout.addWidget(self.path_edit)\n\n        self.browse_btn = QPushButton(\"...\")\n        self.browse_btn.setFixedWidth(40)\n        self.browse_btn.clicked.connect(self._on_browse_destination)\n        self.browse_btn.setStyleSheet(self._button_style(\"#6272A4\"))\n        path_layout.addWidget(self.browse_btn)\n\n        layout.addLayout(path_layout)\n\n        # Mora boxes container\n        mora_container = QHBoxLayout()\n        mora_container.setSpacing(10)\n\n        self.mora_boxes: list[MoraBox] = []\n        for i in range(MORAS_PER_LINE):\n            box = MoraBox(f\"Mora {i+1}\")\n            self.mora_boxes.append(box)\n            mora_container.addWidget(box)\n\n        layout.addLayout(mora_container)\n\n        # Oscilloscope / Waveform\n        self.wave_scope = WaveformScope()\n        self.wave_scope.setFixedHeight(120)\n        layout.addWidget(self.wave_scope)\n\n        # Progress bar\n        self.progress_bar = QProgressBar()\n        self.progress_bar.setMaximum(100)\n        self.progress_bar.setValue(0)\n        self.progress_bar.setStyleSheet(f\"\"\"\n            QProgressBar {{\n                border: 2px solid #3D3D3D;\n                border-radius: 5px;\n                text-align: center;\n                background-color: #252525;\n            }}\n            QProgressBar::chunk {{\n                background-color: {COLORS['accent_recording']};\n            }}\n        \"\"\")\n        layout.addWidget(self.progress_bar)\n\n        # Time label\n        self.time_label = QLabel(\"0.0s / 0.0s\")\n        self.time_label.setAlignment(Qt.AlignmentFlag.AlignCenter)\n        self.time_label.setStyleSheet(f\"color: {COLORS['text_secondary']};\")\n        layout.addWidget(self.time_label)\n\n        # Control buttons\n        button_layout = QHBoxLayout()\n        button_layout.setSpacing(20)\n\n        self.rerecord_btn = QPushButton(\"Iniciar/Re-grabar (Espacio/R)\")\n        self.rerecord_btn.setShortcut(\"Space\")\n        self.rerecord_btn.clicked.connect(self._on_rerecord)\n        self.rerecord_btn.setStyleSheet(self._button_style(\"#FFB86C\"))\n        button_layout.addWidget(self.rerecord_btn)\n\n        self.accept_btn = QPushButton(\"Aceptar (Enter)\")\n        self.accept_btn.setShortcut(\"Return\")\n        self.accept_btn.clicked.connect(self._on_accept)\n        self.accept_btn.setStyleSheet(self._button_style(COLORS['success']))\n        button_layout.addWidget(self.accept_btn)\n\n        self.cancel_btn = QPushButton(\"Cancelar (Esc)\")\n        self.cancel_btn.setShortcut(\"Escape\")\n        self.cancel_btn.clicked.connect(self._on_cancel)\n        self.cancel_btn.setStyleSheet(self._button_style(COLORS['error']))\n        button_layout.addWidget(self.cancel_btn)\n\n        layout.addLayout(button_layout)\n\n        # Listen Button (Extra controls)\n        extra_layout = QHBoxLayout()\n        self.listen_btn = QPushButton(\"\u25b6 Escuchar / Listen\")\n        self.listen_btn.clicked.connect(self._on_listen_clicked)\n        self.listen_btn.setStyleSheet(self._button_style(\"#BD93F9\"))\n        self.listen_btn.setEnabled(False)\n        self.listen_btn.setMinimumWidth(200)\n        extra_layout.addStretch()\n        extra_layout.addWidget(self.listen_btn)\n        extra_layout.addStretch()\n        layout.addLayout(extra_layout)\n\n        # Spacer\n        layout.addStretch()\n\n    def _button_style(self, color: str) -&gt; str:\n        \"\"\"Generate button style with given accent color.\"\"\"\n        return f\"\"\"\n            QPushButton {{\n                background-color: #3D3D3D;\n                color: {COLORS['text_primary']};\n                border: 2px solid {color};\n                border-radius: 8px;\n                padding: 12px 24px;\n                font-size: 14px;\n            }}\n            QPushButton:hover {{\n                background-color: {color};\n                color: #1E1E1E;\n            }}\n            QPushButton:pressed {{\n                background-color: #2D2D2D;\n            }}\n        \"\"\"\n\n    def _setup_timers(self):\n        \"\"\"Setup timing system.\"\"\"\n        self.metronome_timer = QTimer()\n        self.metronome_timer.timeout.connect(self._on_metronome_tick)\n\n        self.progress_timer = QTimer()\n        self.progress_timer.timeout.connect(self._update_progress)\n\n        self.scope_timer = QTimer()\n        self.scope_timer.timeout.connect(self._update_scope)\n        # High-frequency updates for 60 FPS smoothness\n        self.progress_interval = 16 \n        self.scope_interval = 16\n\n    def set_line(self, line: PhoneticLine):\n        \"\"\"Set the current line to record.\n\n        Args:\n            line: PhoneticLine to record\n        \"\"\"\n        self._current_line = line\n        self.line_label.setText(line.raw_text)\n\n        # Update mora boxes with segment text\n        for i, box in enumerate(self.mora_boxes):\n            if i &lt; len(line.segments):\n                box.label.setText(line.segments[i].upper())\n                box.setVisible(True)\n            else:\n                box.setVisible(False)\n\n        self._reset_state()\n\n    def set_bpm(self, bpm: int):\n        \"\"\"Set BPM for metronome.\n\n        Args:\n            bpm: Beats per minute\n        \"\"\"\n        self._bpm = bpm\n\n    def start_recording(self):\n        \"\"\"Start recording with metronome.\"\"\"\n        if not self._current_line:\n            logger.warning(\"No line selected for recording\")\n            return\n\n        self._is_recording = True\n        self._count_in_counter = -self.COUNT_IN_BEATS # Start at -3\n        self._current_mora = 0\n        self._elapsed_ms = 0\n        self._start_time = time.time()\n        self._last_audio = None\n        self.listen_btn.setEnabled(False)\n        self._update_recording_status(True, \"PREPARAR\")\n\n        # Calculate interval and duration\n        ms_per_beat = int(60000 / self._bpm)\n        self.tail_beats = 1\n\n        # Total duration must cover count-in + segments + tail, AND satisfy min duration\n        # Actually count-in is part of the recorded file, so it counts towards duration?\n        # User said: \"Grabaci\u00f3n se inicia desde el segundo 1... tiempo muerto para 3 clicks\"\n        # So yes, count-in is recorded.\n\n        notes_beats = len(self._current_line.segments) + self.tail_beats\n        notes_duration = notes_beats * ms_per_beat\n        countin_duration = self.COUNT_IN_BEATS * ms_per_beat\n\n        # Ensure total duration is at least MIN_RECORDING_DURATION_MS\n        calculated_total = countin_duration + notes_duration\n        self._target_duration_ms = max(self.MIN_RECORDING_DURATION_MS, calculated_total)\n\n        self.progress_bar.setMaximum(self._target_duration_ms)\n\n        # Start persistent output stream for metronome FIRST\n        self.engine.start_output_stream()\n\n        # Start hardware recording\n        try:\n            self.engine.start_recording()\n        except Exception as e:\n            from PyQt6.QtWidgets import QMessageBox\n            QMessageBox.critical(self, \"Error de Audio\", \n                               f\"No se pudo iniciar la grabaci\u00f3n:\\n{str(e)}\\n\\n\"\n                               \"Verifica tu configuraci\u00f3n de audio en Proyecto &gt; Configuraci\u00f3n.\")\n            self._reset_state()\n            self._is_recording = False\n            self.engine.stop_output_stream()\n            return\n\n        # Start timers\n        self.metronome_timer.start(ms_per_beat)\n        self.progress_timer.start(self.progress_interval)\n        self.scope_timer.start(self.scope_interval)\n\n        # Prepare WaveformScope for fixed timeline\n        self.wave_scope.set_mode('fixed', self._target_duration_ms)\n        self.wave_scope.setup_mora_regions(\n            self._bpm, \n            len(self._current_line.segments), \n            self.COUNT_IN_BEATS\n        )\n\n        # Play first count-in click immediately\n        self._play_count_in()\n\n        self.recording_started.emit()\n        logger.info(f\"Recording sequence started: {self._current_line.raw_text}\")\n\n    def _play_count_in(self):\n        \"\"\"Play count-in logic.\"\"\"\n        self.engine.play_click(countin=True)\n        # Visual feedback for count-in\n        count = abs(self._count_in_counter)\n        if count &gt; 0:\n            self._update_recording_status(True, f\"PREPARAR: {count}...\")\n\n    def _reset_state(self):\n        \"\"\"Reset recording state.\"\"\"\n        self._current_mora = 0\n        self._count_in_counter = 0\n        self._elapsed_ms = 0\n        self.progress_bar.setValue(0)\n        self.time_label.setText(\"0.0s / 0.0s\")\n        self.listen_btn.setEnabled(False)\n        self._last_audio = None\n        self.wave_scope.set_mode('scrolling')\n        self.wave_scope.clear()\n\n        for box in self.mora_boxes:\n            box.set_active(False)\n\n        self._update_recording_status(False)\n\n    def _update_recording_status(self, is_recording: bool, text_override: str = None):\n        \"\"\"Update the recording title style.\"\"\"\n        if is_recording:\n            color = COLORS['accent_recording']\n            text = text_override if text_override else \"GRABANDO...\"\n        else:\n            color = COLORS['text_secondary']\n            text = \"GRABANDO\"\n\n        self.title_label.setText(text)\n        self.title_label.setStyleSheet(f\"\"\"\n            font-size: 24px;\n            font-weight: bold;\n            color: {color};\n        \"\"\")\n\n    def _on_metronome_tick(self):\n        \"\"\"Handle metronome tick.\"\"\"\n        # Handle Count-in phase\n        if self._count_in_counter &lt; 0:\n            self._count_in_counter += 1\n            if self._count_in_counter &lt; 0:\n                 self._play_count_in()\n                 return\n            else:\n                 # Count-in finished, start actual recording metrics\n                 self._update_recording_status(True, \"GRABANDO...\")\n                 # Start normal loop below (fall through to index 0)\n\n        # --- Normal Metronome Logic ---\n\n        # Deactivate previous mora visually\n        if self._current_mora &gt; 0 and self._current_mora - 1 &lt; len(self.mora_boxes):\n             self.mora_boxes[self._current_mora - 1].set_active(False)\n\n        # Check if we should stop (based on TIME, not just beats, to enforce min duration)\n        # But we align stopping with beats to be rhythmic.\n        # We stop if we are past the target duration.\n\n        ms_per_beat = int(60000 / self._bpm)\n        current_beat_time = (self._current_mora + self.COUNT_IN_BEATS) * ms_per_beat\n\n        if self._elapsed_ms &gt;= self._target_duration_ms:\n            logger.info(\"Target duration reached, stopping.\")\n            self.stop_recording()\n            return\n\n        # Determine if we are in \"mora\" phase or \"tail/padding\" phase\n        num_segments = len(self._current_line.segments) if self._current_line else 0\n\n        if self._current_mora &lt; num_segments:\n             # Activate box\n             if self._current_mora &lt; len(self.mora_boxes):\n                 self.mora_boxes[self._current_mora].set_active(True)\n             # Play accent/normal click\n             is_first = (self._current_mora == 0)\n             self.engine.play_click(accent=is_first)\n        else:\n             # Tail/Padding phase\n             self.engine.play_click(accent=False)\n\n        self._current_mora += 1\n\n    def _update_scope(self):\n        \"\"\"Update the scrolling waveform plot (DSP).\"\"\"\n        if self._is_recording:\n            # During recording, if in fixed mode, we don't necessarily update the data \n            # unless we implement a real-time waveform builder.\n            # For now, we'll keep it simple and just update the playhead.\n            # But we could optionally keep scrolling the scope if wanted.\n            pass\n        else:\n            data = self.engine.get_scope_data()\n            self.wave_scope.update_data(data)\n\n    def _update_progress(self):\n        \"\"\"Update progress bar, time display and playhead.\"\"\"\n        if not self._is_recording and not self.engine.is_playing():\n            if not self.engine.is_playing() and self.progress_timer.isActive():\n                self.progress_timer.stop()\n            return\n\n        if self._is_recording:\n            # Real-time sync during recording\n            elapsed_real = (time.time() - self._start_time) * 1000\n            self._elapsed_ms = int(elapsed_real)\n        else:\n            # Sync with playback engine\n            self._elapsed_ms = int(self.engine.get_playback_progress())\n\n        self.progress_bar.setValue(self._elapsed_ms)\n        self.wave_scope.set_playhead(self._elapsed_ms)\n\n        elapsed_s = self._elapsed_ms / 1000\n        total_s = self._target_duration_ms / 1000 if self._is_recording else (len(self._last_audio) / self.engine._active_sr if self._last_audio is not None else 0)\n\n        self.time_label.setText(f\"{elapsed_s:.1f}s / {total_s:.1f}s\")\n\n    def _on_rerecord(self):\n        \"\"\"Handle re-record button.\"\"\"\n        self.stop_recording()\n        self._reset_state()\n        self.start_recording()\n\n    def _on_accept(self):\n        \"\"\"Handle accept button.\"\"\"\n        # Fix 44-byte bug (M5.1): Don't stop if already stopped, just save what we have\n        if self._is_recording:\n            self.stop_recording()\n\n        # Save audio if a line is selected and we have a path\n        if self._current_line and self._last_audio is not None and len(self._last_audio) &gt; 0:\n             wav_name = f\"{self._current_line.raw_text}.wav\"\n             save_file = Path(self.path_edit.text()) / wav_name\n             try:\n                 self.engine.save_wav(self._last_audio, str(save_file))\n                 logger.info(f\"Auto-saved recording to: {save_file}\")\n             except Exception as e:\n                 logger.error(f\"Failed to auto-save recording: {e}\")\n\n        # Return recorded audio\n        self.recording_stopped.emit(self._last_audio)\n\n    def _on_cancel(self):\n        \"\"\"Handle cancel button.\"\"\"\n        self.stop_recording()\n        self._reset_state()\n        self.recording_cancelled.emit()\n\n    def _on_browse_destination(self):\n        \"\"\"Open dialog to select destination folder.\"\"\"\n        folder = QFileDialog.getExistingDirectory(\n            self, \"Seleccionar carpeta de destino\", str(self._dest_path)\n        )\n        if folder:\n            self._dest_path = Path(folder)\n            self.path_edit.setText(folder)\n            logger.info(f\"Destination path changed to: {folder}\")\n\n    def _on_listen_clicked(self):\n        \"\"\"Play back the last recorded audio with visual sync.\"\"\"\n        if self._last_audio is not None:\n            # Prepare UI for playback\n            duration_ms = (len(self._last_audio) / self.engine._active_sr) * 1000\n            self.progress_bar.setMaximum(int(duration_ms))\n\n            self.wave_scope.set_mode('fixed', duration_ms)\n            self.wave_scope.set_waveform(self._last_audio, self.engine._active_sr)\n            # Re-draw regions for playback (no count-in offset here because we play recorded audio only)\n            # BUT the recorded audio INCLUDES the count-in silence! \n            # So we keep the same region setup.\n            self.wave_scope.setup_mora_regions(\n                self._bpm, \n                len(self._current_line.segments), \n                self.COUNT_IN_BEATS\n            )\n\n            self.engine.play_audio(self._last_audio)\n            self.progress_timer.start(50) # Faster updates for smooth playhead\n        else:\n            logger.warning(\"No audio to play\")\n\n    def stop_recording(self):\n        \"\"\"Stop recording.\"\"\"\n        self._is_recording = False\n        self.metronome_timer.stop()\n        self.progress_timer.stop()\n        self.scope_timer.stop()\n\n        # Stop hardware recording AND output stream\n        self._last_audio = self.engine.stop_recording()\n        self.engine.stop_output_stream()\n\n        if self._last_audio is not None and len(self._last_audio) &gt; 0:\n            self.listen_btn.setEnabled(True)\n\n        self._update_recording_status(False)\n        logger.info(\"Recording stopped\")\n</code></pre>"},{"location":"reference/ui/#ui.recorder_widget.RecorderWidget.set_bpm","title":"<code>set_bpm(bpm)</code>","text":"<p>Set BPM for metronome.</p> <p>Parameters:</p> Name Type Description Default <code>bpm</code> <code>int</code> <p>Beats per minute</p> required Source code in <code>src/ui/recorder_widget.py</code> <pre><code>def set_bpm(self, bpm: int):\n    \"\"\"Set BPM for metronome.\n\n    Args:\n        bpm: Beats per minute\n    \"\"\"\n    self._bpm = bpm\n</code></pre>"},{"location":"reference/ui/#ui.recorder_widget.RecorderWidget.set_line","title":"<code>set_line(line)</code>","text":"<p>Set the current line to record.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>PhoneticLine</code> <p>PhoneticLine to record</p> required Source code in <code>src/ui/recorder_widget.py</code> <pre><code>def set_line(self, line: PhoneticLine):\n    \"\"\"Set the current line to record.\n\n    Args:\n        line: PhoneticLine to record\n    \"\"\"\n    self._current_line = line\n    self.line_label.setText(line.raw_text)\n\n    # Update mora boxes with segment text\n    for i, box in enumerate(self.mora_boxes):\n        if i &lt; len(line.segments):\n            box.label.setText(line.segments[i].upper())\n            box.setVisible(True)\n        else:\n            box.setVisible(False)\n\n    self._reset_state()\n</code></pre>"},{"location":"reference/ui/#ui.recorder_widget.RecorderWidget.start_recording","title":"<code>start_recording()</code>","text":"<p>Start recording with metronome.</p> Source code in <code>src/ui/recorder_widget.py</code> <pre><code>def start_recording(self):\n    \"\"\"Start recording with metronome.\"\"\"\n    if not self._current_line:\n        logger.warning(\"No line selected for recording\")\n        return\n\n    self._is_recording = True\n    self._count_in_counter = -self.COUNT_IN_BEATS # Start at -3\n    self._current_mora = 0\n    self._elapsed_ms = 0\n    self._start_time = time.time()\n    self._last_audio = None\n    self.listen_btn.setEnabled(False)\n    self._update_recording_status(True, \"PREPARAR\")\n\n    # Calculate interval and duration\n    ms_per_beat = int(60000 / self._bpm)\n    self.tail_beats = 1\n\n    # Total duration must cover count-in + segments + tail, AND satisfy min duration\n    # Actually count-in is part of the recorded file, so it counts towards duration?\n    # User said: \"Grabaci\u00f3n se inicia desde el segundo 1... tiempo muerto para 3 clicks\"\n    # So yes, count-in is recorded.\n\n    notes_beats = len(self._current_line.segments) + self.tail_beats\n    notes_duration = notes_beats * ms_per_beat\n    countin_duration = self.COUNT_IN_BEATS * ms_per_beat\n\n    # Ensure total duration is at least MIN_RECORDING_DURATION_MS\n    calculated_total = countin_duration + notes_duration\n    self._target_duration_ms = max(self.MIN_RECORDING_DURATION_MS, calculated_total)\n\n    self.progress_bar.setMaximum(self._target_duration_ms)\n\n    # Start persistent output stream for metronome FIRST\n    self.engine.start_output_stream()\n\n    # Start hardware recording\n    try:\n        self.engine.start_recording()\n    except Exception as e:\n        from PyQt6.QtWidgets import QMessageBox\n        QMessageBox.critical(self, \"Error de Audio\", \n                           f\"No se pudo iniciar la grabaci\u00f3n:\\n{str(e)}\\n\\n\"\n                           \"Verifica tu configuraci\u00f3n de audio en Proyecto &gt; Configuraci\u00f3n.\")\n        self._reset_state()\n        self._is_recording = False\n        self.engine.stop_output_stream()\n        return\n\n    # Start timers\n    self.metronome_timer.start(ms_per_beat)\n    self.progress_timer.start(self.progress_interval)\n    self.scope_timer.start(self.scope_interval)\n\n    # Prepare WaveformScope for fixed timeline\n    self.wave_scope.set_mode('fixed', self._target_duration_ms)\n    self.wave_scope.setup_mora_regions(\n        self._bpm, \n        len(self._current_line.segments), \n        self.COUNT_IN_BEATS\n    )\n\n    # Play first count-in click immediately\n    self._play_count_in()\n\n    self.recording_started.emit()\n    logger.info(f\"Recording sequence started: {self._current_line.raw_text}\")\n</code></pre>"},{"location":"reference/ui/#ui.recorder_widget.RecorderWidget.stop_recording","title":"<code>stop_recording()</code>","text":"<p>Stop recording.</p> Source code in <code>src/ui/recorder_widget.py</code> <pre><code>def stop_recording(self):\n    \"\"\"Stop recording.\"\"\"\n    self._is_recording = False\n    self.metronome_timer.stop()\n    self.progress_timer.stop()\n    self.scope_timer.stop()\n\n    # Stop hardware recording AND output stream\n    self._last_audio = self.engine.stop_recording()\n    self.engine.stop_output_stream()\n\n    if self._last_audio is not None and len(self._last_audio) &gt; 0:\n        self.listen_btn.setEnabled(True)\n\n    self._update_recording_status(False)\n    logger.info(\"Recording stopped\")\n</code></pre>"},{"location":"reference/ui/#ui.editor_widget.EditorWidget","title":"<code>EditorWidget</code>","text":"<p>               Bases: <code>QWidget</code></p> <p>Visual editor container.</p> Source code in <code>src/ui/editor_widget.py</code> <pre><code>class EditorWidget(QWidget):\n    \"\"\"Visual editor container.\"\"\"\n\n    # Re-emit signals from canvas or nav\n    marker_moved = pyqtSignal(str, float)\n    play_requested = pyqtSignal()\n    next_requested = pyqtSignal()\n    prev_requested = pyqtSignal()\n\n    # Request to set marker at current playhead or mouse\n    marker_set_requested = pyqtSignal(str) # param_name\n\n    def __init__(self, parent=None):\n        super().__init__(parent)\n        self._current_entry: Optional[OtoEntry] = None\n\n        # Enable focus for keyboard shortcuts\n        self.setFocusPolicy(Qt.FocusPolicy.StrongFocus)\n        self._setup_ui()\n\n    def _setup_ui(self):\n        \"\"\"Setup widget UI.\"\"\"\n        layout = QVBoxLayout(self)\n        layout.setContentsMargins(10, 10, 10, 10)\n\n        # Title/Header\n        self.label_alias = QLabel(\"No Alias Selected\")\n        self.label_alias.setStyleSheet(f\"\"\"\n            font-size: 18px; \n            font-weight: bold; \n            color: {COLORS['text_primary']};\n        \"\"\")\n\n        header_layout = QHBoxLayout()\n        header_layout.addWidget(self.label_alias)\n        header_layout.addStretch()\n\n        self.search_bar = QLineEdit()\n        self.search_bar.setPlaceholderText(\"\ud83d\udd0d Buscar grabaci\u00f3n...\")\n        self.search_bar.setFixedWidth(200)\n        self.search_bar.setStyleSheet(f\"\"\"\n            background-color: #2D2D2D;\n            color: white;\n            border: 1px solid #3D3D3D;\n            border-radius: 4px;\n            padding: 4px;\n        \"\"\")\n        header_layout.addWidget(self.search_bar)\n\n        layout.addLayout(header_layout)\n\n        # Canvas\n        self.canvas = WaveformCanvas()\n        self.canvas.marker_moved.connect(self.marker_moved.emit)\n        layout.addWidget(self.canvas, stretch=1)\n\n        # Navigation\n        nav_layout = QHBoxLayout()\n\n        self.btn_play = QPushButton(\"\u25b6 Play (Space)\")\n        self.btn_play.setShortcut(\"Space\")\n        self.btn_play.clicked.connect(self.play_requested.emit)\n        nav_layout.addWidget(self.btn_play)\n\n        self.btn_prev = QPushButton(\"\u25c0 Prev\")\n        self.btn_prev.clicked.connect(self.prev_requested.emit)\n        nav_layout.addWidget(self.btn_prev)\n\n        self.btn_next = QPushButton(\"Next \u25b6\")\n        self.btn_next.clicked.connect(self.next_requested.emit)\n        nav_layout.addWidget(self.btn_next)\n\n        layout.addLayout(nav_layout)\n\n    def set_entry(self, entry: OtoEntry):\n        \"\"\"Update view with new entry.\"\"\"\n        self._current_entry = entry\n        if entry:\n            self.label_alias.setText(f\"Alias: {entry.alias}\")\n            self.canvas.set_markers(entry)\n        else:\n            self.label_alias.setText(\"No Selection\")\n\n    def set_audio_data(self, audio: np.ndarray, sr: int, spectrogram: np.ndarray = None, rms: np.ndarray = None):\n        \"\"\"Pass audio data to canvas.\"\"\"\n        self.canvas.set_audio_data(audio, sr, spectrogram, rms)\n\n    def keyPressEvent(self, event):\n        \"\"\"Handle global editor shortcuts.\"\"\"\n        key = event.key()\n\n        if key == Qt.Key.Key_F1:\n            self.marker_set_requested.emit('left_blank')\n        elif key == Qt.Key.Key_F2:\n            self.marker_set_requested.emit('overlap')\n        elif key == Qt.Key.Key_F3:\n            self.marker_set_requested.emit('preutter')\n        elif key == Qt.Key.Key_F4:\n            self.marker_set_requested.emit('fixed')\n        elif key == Qt.Key.Key_F5:\n            self.marker_set_requested.emit('right_blank')\n        else:\n            super().keyPressEvent(event)\n</code></pre>"},{"location":"reference/ui/#ui.editor_widget.EditorWidget.keyPressEvent","title":"<code>keyPressEvent(event)</code>","text":"<p>Handle global editor shortcuts.</p> Source code in <code>src/ui/editor_widget.py</code> <pre><code>def keyPressEvent(self, event):\n    \"\"\"Handle global editor shortcuts.\"\"\"\n    key = event.key()\n\n    if key == Qt.Key.Key_F1:\n        self.marker_set_requested.emit('left_blank')\n    elif key == Qt.Key.Key_F2:\n        self.marker_set_requested.emit('overlap')\n    elif key == Qt.Key.Key_F3:\n        self.marker_set_requested.emit('preutter')\n    elif key == Qt.Key.Key_F4:\n        self.marker_set_requested.emit('fixed')\n    elif key == Qt.Key.Key_F5:\n        self.marker_set_requested.emit('right_blank')\n    else:\n        super().keyPressEvent(event)\n</code></pre>"},{"location":"reference/ui/#ui.editor_widget.EditorWidget.set_audio_data","title":"<code>set_audio_data(audio, sr, spectrogram=None, rms=None)</code>","text":"<p>Pass audio data to canvas.</p> Source code in <code>src/ui/editor_widget.py</code> <pre><code>def set_audio_data(self, audio: np.ndarray, sr: int, spectrogram: np.ndarray = None, rms: np.ndarray = None):\n    \"\"\"Pass audio data to canvas.\"\"\"\n    self.canvas.set_audio_data(audio, sr, spectrogram, rms)\n</code></pre>"},{"location":"reference/ui/#ui.editor_widget.EditorWidget.set_entry","title":"<code>set_entry(entry)</code>","text":"<p>Update view with new entry.</p> Source code in <code>src/ui/editor_widget.py</code> <pre><code>def set_entry(self, entry: OtoEntry):\n    \"\"\"Update view with new entry.\"\"\"\n    self._current_entry = entry\n    if entry:\n        self.label_alias.setText(f\"Alias: {entry.alias}\")\n        self.canvas.set_markers(entry)\n    else:\n        self.label_alias.setText(\"No Selection\")\n</code></pre>"}]}